{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2afd9a5",
   "metadata": {},
   "source": [
    "## Antiguo proyecto de Redes Neuronales Recurrentes usando audios .wav, obteniendo su MFCC, aplicandolos a una RNN y validandolo con k fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37415a0a",
   "metadata": {},
   "source": [
    "#### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbcf75ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import soundfile as sf\n",
    "import json\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "import datetime\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4830c4a",
   "metadata": {},
   "source": [
    "#### Funciones a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6ffb974",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Obtiene el path con el nombre de todos los archivos de un directorio.\n",
    "def get_files_from_path(directory):\n",
    "    path_files = []\n",
    "    dir_list = os.listdir(directory)\n",
    "    for path in dir_list:\n",
    "        path_files.append(directory+\"\\\\\"+path)\n",
    "    return path_files\n",
    "\n",
    "\n",
    "#Extrae los paths que cumplan con un codigo\n",
    "def extract_paths_for_emotions_keys(emotions_code, files_path, get_code):\n",
    "    paths = []\n",
    "    emotions_set = set(emotions_code)\n",
    "    for code_file in files_path:\n",
    "        if (get_code(code_file) in emotions_set):\n",
    "            paths.append(code_file)\n",
    "    return paths\n",
    "\n",
    "\n",
    "#Obtiene el codigo en el nombre del archivo para el dataset ASSVM (dataset en español)\n",
    "def get_code_esp(path):\n",
    "    return path[114]#path[110] prueba\n",
    "\n",
    "#Obtiene el codigo en el nombre del archivo para el dataset CREMA-D\n",
    "def get_code_crema_d(path):\n",
    "    return path[119:122]\n",
    "\n",
    "\n",
    "#Obtiene el codigo en el nombre del archivo para el dataset SAVEE\n",
    "def get_code_savee(path):\n",
    "    return path[108]\n",
    "\n",
    "#Esta función abre el archivo .wav y obtiene el mfcc escalado en un vector de 40 elementos, lanza un mensaje si sucedio un error\n",
    "def features_extractor(file_name):\n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "        mfccs_features = librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=40)\n",
    "        mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n",
    "        return mfccs_scaled_features\n",
    "    except:\n",
    "        print(\"error-\", file_name)\n",
    "\n",
    "\n",
    "#Esta función permite guardar los MFCC en 'features', el código en 'code' y su dirección en 'path' en un archivo .json.\n",
    "def save_elements_in_json(examples_saved, name):\n",
    "    json_files = []\n",
    "    json_file = {}\n",
    "    index = 0\n",
    "    for file in examples_saved:\n",
    "        json_file = {\"id\": index, \"features\":[str(elem) for elem in file[0]] ,\"code\":file[1], \"path\":file[2]}\n",
    "        json_files.append(json_file)\n",
    "        index += 1\n",
    "    json_object = json.dumps(json_files)\n",
    "    with open(f\"{name}.json\", \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "   \n",
    "\n",
    "#La función permite cargar datos del MFCC y código desde un archivo .json.\n",
    "def load_elements_from_json(name):\n",
    "    f = open(f'{name}.json')\n",
    "    data = json.load(f)\n",
    "    examples = []\n",
    "    for element in data:\n",
    "        examples.append(([float(feature) for feature in (element[\"features\"])], element[\"code\"]))\n",
    "    return examples\n",
    "\n",
    "\n",
    "#La función nos permite devolver una lista de MFCC obtenidos de una lista de paths. \n",
    "#El MFCC tiene un límite que no le permite cargar archivos menor o igual a 44 kb.\n",
    "#Con el diccionario obtenemos el total de audios recuperados por emoción.\n",
    "def get_features(paths,get_code, files_filters = dict()):\n",
    "    examples = []\n",
    "    for path in paths:\n",
    "        code = get_code(path)\n",
    "        file_stats = os.stat(path)\n",
    "        feature = features_extractor(path)\n",
    "        files_filters[code]+= 1\n",
    "        examples.append((feature,code))\n",
    "    print(f\"Se obtuvo el MFCC de unos {len(paths)} sobre {sum(files_filters[files] for files in files_filters)} audios.\")\n",
    "    return examples\n",
    "\n",
    "\n",
    "#Selecciona n ejemplos que necesitemos y los mezcla.\n",
    "def select_elements(examples, code, quantity, new_code):\n",
    "    random.shuffle(examples)\n",
    "    elements = []\n",
    "    counter = 1\n",
    "    for example in examples:\n",
    "        if (counter > quantity):\n",
    "            break\n",
    "        if code == example[1]:\n",
    "            elements.append((example[0],new_code))\n",
    "            counter = counter + 1\n",
    "    return elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78e14ce",
   "metadata": {},
   "source": [
    "Los siguientes bloques obtienen los paths y filtra las emociones que necesitemos en cada dataset (CREMA-D y SAVEE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97450846",
   "metadata": {},
   "source": [
    "#### Funciones para obtener los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13f7c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtiene todos los datos de CREMA-D y SAVEE  \n",
    "def get_datas():\n",
    "    files_path = get_files_from_path(f\"{os.getcwd()}\\\\..\\\\..\\\\Datasets\\\\data\")\n",
    "    emotions_code = [\"t\", \"f\"]\n",
    "    datas_files = extract_paths_for_emotions_keys(emotions_code, files_path, get_code_esp)\n",
    "    examples = []\n",
    "    files_filters = dict()\n",
    "    files_filters[\"t\"] = 0\n",
    "    files_filters[\"f\"] = 0\n",
    "    examples = get_features(datas_files, get_code_esp, files_filters)\n",
    "    return examples\n",
    "\n",
    "#Obtiene los datos de entrada para la red neuronal x: mfcc normalizados, y: labeles categorizados\n",
    "def get_entries():\n",
    "    all_examples = get_datas()\n",
    "    entries = []\n",
    "    for example in all_examples:\n",
    "        entries.append((example[0], example[1]))\n",
    "    datas = select_elements(entries, 't', 800,\"without_stress\")\n",
    "    datas += select_elements(entries, 'f', 800, \"stress\")\n",
    "    random.shuffle(datas)\n",
    "    X = []\n",
    "    y = []\n",
    "    for data in datas:\n",
    "        X.append(data[0])\n",
    "        y.append(data[1])\n",
    "    labelencoder=preprocessing.LabelEncoder()\n",
    "    y = to_categorical(labelencoder.fit_transform(y))\n",
    "    return X, y\n",
    "\n",
    "#Obtiene los datos divididos de entrenamiento y tests\n",
    "def obtain_datas_train_and_test(percentage):\n",
    "    X, y = get_entries()\n",
    "    \n",
    "    X_test, X_train, y_test, y_train = train_test_split(X, y, test_size =percentage,random_state=0)\n",
    "    y = np.array(y)\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "995eff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio = time.time()  # Guarda el tiempo de inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff362da0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtuvo el MFCC de unos 1600 sobre 1600 audios.\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = obtain_datas_train_and_test(0.8)\n",
    "num_labels = y_train.shape[1] + y_test.shape[1]\n",
    "dim_entrada = (X_train.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22fde56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146.53162145614624 seg\n"
     ]
    }
   ],
   "source": [
    "fin = time.time()  # Guarda el tiempo de finalización\n",
    "print(fin - inicio, \"seg\")  # Calcula la duración en segundos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc211300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#probando nueva arquitectura\n",
    "def new_RNN():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50,input_shape= dim_entrada, return_sequences=True))\n",
    "    model.add(LSTM(units=50,input_shape= dim_entrada, return_sequences=False))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "111940c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_9 (LSTM)               (None, 40, 50)            10400     \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 50)                0         \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 50)                0         \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 50)                0         \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,702\n",
      "Trainable params: 30,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = new_RNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bc2e9ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 40, 50)            10400     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 50)                0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,702\n",
      "Trainable params: 30,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "40/40 [==============================] - 13s 141ms/step - loss: 0.6984 - accuracy: 0.4977 - val_loss: 0.6922 - val_accuracy: 0.5281\n",
      "Epoch 2/60\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.6953 - accuracy: 0.4977 - val_loss: 0.6925 - val_accuracy: 0.5250\n",
      "Epoch 3/60\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.6950 - accuracy: 0.4938 - val_loss: 0.6929 - val_accuracy: 0.5250\n",
      "Epoch 4/60\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.6948 - accuracy: 0.4984 - val_loss: 0.6927 - val_accuracy: 0.5219\n",
      "Epoch 5/60\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.6951 - accuracy: 0.5023 - val_loss: 0.6964 - val_accuracy: 0.4750\n",
      "Epoch 6/60\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.6923 - accuracy: 0.5250 - val_loss: 0.6904 - val_accuracy: 0.5437\n",
      "Epoch 7/60\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.6933 - accuracy: 0.5047 - val_loss: 0.6938 - val_accuracy: 0.5031\n",
      "Epoch 8/60\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.6907 - accuracy: 0.4945 - val_loss: 0.6963 - val_accuracy: 0.4875\n",
      "Epoch 9/60\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.6929 - accuracy: 0.5008 - val_loss: 0.6922 - val_accuracy: 0.5375\n",
      "Epoch 10/60\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.6915 - accuracy: 0.5234 - val_loss: 0.6908 - val_accuracy: 0.5156\n",
      "Epoch 11/60\n",
      "40/40 [==============================] - 3s 83ms/step - loss: 0.6906 - accuracy: 0.5289 - val_loss: 0.7078 - val_accuracy: 0.4594\n",
      "Epoch 12/60\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 0.6894 - accuracy: 0.5234 - val_loss: 0.6994 - val_accuracy: 0.4563\n",
      "Epoch 13/60\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.6873 - accuracy: 0.5320 - val_loss: 0.6978 - val_accuracy: 0.4719\n",
      "Epoch 14/60\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.6882 - accuracy: 0.5180 - val_loss: 0.6998 - val_accuracy: 0.4750\n",
      "Epoch 15/60\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.6870 - accuracy: 0.5484 - val_loss: 0.6975 - val_accuracy: 0.4844\n",
      "Epoch 16/60\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.6823 - accuracy: 0.5547 - val_loss: 0.6978 - val_accuracy: 0.4844\n",
      "Epoch 17/60\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.6845 - accuracy: 0.5523 - val_loss: 0.6929 - val_accuracy: 0.5188\n",
      "Epoch 18/60\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.6908 - accuracy: 0.5281 - val_loss: 0.6987 - val_accuracy: 0.4938\n",
      "Epoch 19/60\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.6831 - accuracy: 0.5398 - val_loss: 0.7072 - val_accuracy: 0.4938\n",
      "Epoch 20/60\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.6813 - accuracy: 0.5578 - val_loss: 0.6961 - val_accuracy: 0.4844\n",
      "Epoch 21/60\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.6785 - accuracy: 0.5500 - val_loss: 0.7032 - val_accuracy: 0.4938\n",
      "Epoch 22/60\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.6791 - accuracy: 0.5508 - val_loss: 0.7016 - val_accuracy: 0.4812\n",
      "Epoch 23/60\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.6759 - accuracy: 0.5703 - val_loss: 0.7067 - val_accuracy: 0.4688\n",
      "Epoch 24/60\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.6735 - accuracy: 0.5539 - val_loss: 0.6985 - val_accuracy: 0.5125\n",
      "Epoch 25/60\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.6756 - accuracy: 0.5484 - val_loss: 0.7058 - val_accuracy: 0.4875\n",
      "Epoch 26/60\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.6706 - accuracy: 0.5672 - val_loss: 0.6893 - val_accuracy: 0.5281\n",
      "Epoch 27/60\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.6706 - accuracy: 0.5656 - val_loss: 0.7008 - val_accuracy: 0.5156\n",
      "Epoch 28/60\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.6690 - accuracy: 0.5750 - val_loss: 0.6934 - val_accuracy: 0.5125\n",
      "Epoch 29/60\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 0.6611 - accuracy: 0.5820 - val_loss: 0.7118 - val_accuracy: 0.4844\n",
      "Epoch 30/60\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.6565 - accuracy: 0.5813 - val_loss: 0.7463 - val_accuracy: 0.4938\n",
      "Epoch 31/60\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.6586 - accuracy: 0.5719 - val_loss: 0.7034 - val_accuracy: 0.4906\n",
      "Epoch 32/60\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.6618 - accuracy: 0.5852 - val_loss: 0.6970 - val_accuracy: 0.5281\n",
      "Epoch 33/60\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.6531 - accuracy: 0.5711 - val_loss: 0.6936 - val_accuracy: 0.5312\n",
      "Epoch 34/60\n",
      "40/40 [==============================] - 3s 73ms/step - loss: 0.6532 - accuracy: 0.5906 - val_loss: 0.6995 - val_accuracy: 0.5562\n",
      "Epoch 35/60\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 0.6571 - accuracy: 0.5797 - val_loss: 0.7030 - val_accuracy: 0.5219\n",
      "Epoch 36/60\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.6530 - accuracy: 0.5727 - val_loss: 0.7087 - val_accuracy: 0.4812\n",
      "Epoch 37/60\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.6529 - accuracy: 0.5945 - val_loss: 0.7005 - val_accuracy: 0.5594\n",
      "Epoch 38/60\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.6457 - accuracy: 0.5961 - val_loss: 0.7014 - val_accuracy: 0.5437\n",
      "Epoch 39/60\n",
      "40/40 [==============================] - 4s 93ms/step - loss: 0.6461 - accuracy: 0.6008 - val_loss: 0.6860 - val_accuracy: 0.5562\n",
      "Epoch 40/60\n",
      "40/40 [==============================] - 3s 84ms/step - loss: 0.6372 - accuracy: 0.6187 - val_loss: 0.7033 - val_accuracy: 0.5781\n",
      "Epoch 41/60\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.6409 - accuracy: 0.6164 - val_loss: 0.6855 - val_accuracy: 0.5531\n",
      "Epoch 42/60\n",
      "40/40 [==============================] - 3s 87ms/step - loss: 0.6305 - accuracy: 0.6180 - val_loss: 0.7380 - val_accuracy: 0.5219\n",
      "Epoch 43/60\n",
      "40/40 [==============================] - 4s 97ms/step - loss: 0.6273 - accuracy: 0.6156 - val_loss: 0.6966 - val_accuracy: 0.5813\n",
      "Epoch 44/60\n",
      "40/40 [==============================] - 3s 85ms/step - loss: 0.6207 - accuracy: 0.6273 - val_loss: 0.7322 - val_accuracy: 0.5906\n",
      "Epoch 45/60\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.6156 - accuracy: 0.6289 - val_loss: 0.7269 - val_accuracy: 0.5469\n",
      "Epoch 46/60\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.6190 - accuracy: 0.6234 - val_loss: 0.7298 - val_accuracy: 0.5656\n",
      "Epoch 47/60\n",
      "40/40 [==============================] - 3s 81ms/step - loss: 0.6022 - accuracy: 0.6555 - val_loss: 0.6896 - val_accuracy: 0.5656\n",
      "Epoch 48/60\n",
      "40/40 [==============================] - 3s 75ms/step - loss: 0.6078 - accuracy: 0.6375 - val_loss: 0.6842 - val_accuracy: 0.5938\n",
      "Epoch 49/60\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.5966 - accuracy: 0.6578 - val_loss: 0.6856 - val_accuracy: 0.5813\n",
      "Epoch 50/60\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.5829 - accuracy: 0.6719 - val_loss: 0.7065 - val_accuracy: 0.5875\n",
      "Epoch 51/60\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.5837 - accuracy: 0.6539 - val_loss: 0.7224 - val_accuracy: 0.6000\n",
      "Epoch 52/60\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 0.5738 - accuracy: 0.6641 - val_loss: 0.7114 - val_accuracy: 0.5969\n",
      "Epoch 53/60\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 0.5743 - accuracy: 0.6594 - val_loss: 0.7171 - val_accuracy: 0.6000\n",
      "Epoch 54/60\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 0.5584 - accuracy: 0.6812 - val_loss: 0.7381 - val_accuracy: 0.5938\n",
      "Epoch 55/60\n",
      "40/40 [==============================] - 3s 76ms/step - loss: 0.5507 - accuracy: 0.6844 - val_loss: 0.7170 - val_accuracy: 0.6062\n",
      "Epoch 56/60\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 0.5527 - accuracy: 0.6812 - val_loss: 0.7052 - val_accuracy: 0.6094\n",
      "Epoch 57/60\n",
      "40/40 [==============================] - 4s 94ms/step - loss: 0.5167 - accuracy: 0.7188 - val_loss: 0.7503 - val_accuracy: 0.6062\n",
      "Epoch 58/60\n",
      "40/40 [==============================] - 3s 87ms/step - loss: 0.5471 - accuracy: 0.6930 - val_loss: 0.7378 - val_accuracy: 0.6031\n",
      "Epoch 59/60\n",
      "40/40 [==============================] - 4s 91ms/step - loss: 0.5261 - accuracy: 0.7086 - val_loss: 0.7334 - val_accuracy: 0.6219\n",
      "Epoch 60/60\n",
      "40/40 [==============================] - 4s 95ms/step - loss: 0.5146 - accuracy: 0.7195 - val_loss: 0.7024 - val_accuracy: 0.6375\n",
      "val_loss: 0.7023897171020508 val_accuracy: 0.637499988079071\n",
      "10/10 [==============================] - 3s 34ms/step\n",
      "El algoritmo acerto 204 veces sobre los 320 casos.\n"
     ]
    }
   ],
   "source": [
    "model = new_RNN()\n",
    "model.summary()\n",
    "callbacks = []\n",
    "'''\n",
    "#https://keras.io/api/callbacks/early_stopping/\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        min_delta=0.01, #si un epochs mejora como un min_delta respecto a la anterior, no contara como mejora\n",
    "        patience=70,#numero de epochs sin mejoras que se tendra paciencia\n",
    "        verbose=1,#mostrar informacion extra, 0 no mostrar\n",
    "     )\n",
    "]\n",
    "'''\n",
    "num_epochs = 50\n",
    "num_batch_size = 32\n",
    "start = datetime.datetime.now()\n",
    "   \n",
    "results = model.fit(X_train, y_train, batch_size=num_batch_size,epochs=num_epochs, validation_data=(X_test, y_test),callbacks=callbacks)\n",
    "duration = datetime.datetime.now() - start\n",
    "test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"val_loss: {test_accuracy[0]}\", f\"val_accuracy: {test_accuracy[1]}\")\n",
    "y_values = model.predict(X_test)\n",
    "y_prediction=[([1,0] if i[0]>i[1] else [0,1]) for i in y_values]\n",
    "y_i = len(y_values)\n",
    "i = 0\n",
    "true_values = 0\n",
    "while (i < y_i):\n",
    "    true_values += (1 if (y_test[i][0] == y_prediction[i][0] or y_test[i][1] == y_prediction[i][1]) else 0)\n",
    "    i = i + 1 \n",
    "print(f\"El algoritmo acerto {true_values} veces sobre los {y_i} casos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47073eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = results.history['loss']\n",
    "test_loss = results.history['val_loss']\n",
    "epochs_range = range(1, len(training_loss) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe63342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9532d8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold #1\n",
      "Train - X:(1280, 40) y:(1280, 2)\n",
      "Test - X:(320, 40) y:(320, 2)\n",
      "Epoch 1/60\n",
      "40/40 [==============================] - 8s 113ms/step - loss: 0.6994 - accuracy: 0.5078 - val_loss: 0.6972 - val_accuracy: 0.4938\n",
      "Epoch 2/60\n",
      "40/40 [==============================] - 4s 90ms/step - loss: 0.6939 - accuracy: 0.5016 - val_loss: 0.6925 - val_accuracy: 0.5094\n",
      "Epoch 3/60\n",
      "40/40 [==============================] - 4s 88ms/step - loss: 0.6971 - accuracy: 0.5016 - val_loss: 0.6928 - val_accuracy: 0.5000\n",
      "Epoch 4/60\n",
      "40/40 [==============================] - 4s 88ms/step - loss: 0.6959 - accuracy: 0.5008 - val_loss: 0.6915 - val_accuracy: 0.5406\n",
      "Epoch 5/60\n",
      "40/40 [==============================] - 3s 74ms/step - loss: 0.6933 - accuracy: 0.5250 - val_loss: 0.6914 - val_accuracy: 0.4938\n",
      "Epoch 6/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6915 - accuracy: 0.5227 - val_loss: 0.6905 - val_accuracy: 0.5063\n",
      "Epoch 7/60\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.6955 - accuracy: 0.5023 - val_loss: 0.6911 - val_accuracy: 0.5063\n",
      "Epoch 8/60\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.6941 - accuracy: 0.5164 - val_loss: 0.6905 - val_accuracy: 0.4969\n",
      "Epoch 9/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6932 - accuracy: 0.5289 - val_loss: 0.6894 - val_accuracy: 0.5156\n",
      "Epoch 10/60\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 0.6912 - accuracy: 0.5133 - val_loss: 0.6892 - val_accuracy: 0.5063\n",
      "Epoch 11/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6927 - accuracy: 0.4977 - val_loss: 0.6890 - val_accuracy: 0.5000\n",
      "Epoch 12/60\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 0.6928 - accuracy: 0.5102 - val_loss: 0.6927 - val_accuracy: 0.5094\n",
      "Epoch 13/60\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 0.6932 - accuracy: 0.5172 - val_loss: 0.6933 - val_accuracy: 0.4906\n",
      "Epoch 14/60\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.6905 - accuracy: 0.5328 - val_loss: 0.6923 - val_accuracy: 0.5031\n",
      "Epoch 15/60\n",
      "40/40 [==============================] - 1s 34ms/step - loss: 0.6933 - accuracy: 0.4891 - val_loss: 0.6917 - val_accuracy: 0.5000\n",
      "Epoch 16/60\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.6930 - accuracy: 0.5016 - val_loss: 0.6895 - val_accuracy: 0.5406\n",
      "Epoch 17/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6911 - accuracy: 0.5148 - val_loss: 0.6885 - val_accuracy: 0.5156\n",
      "Epoch 18/60\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.6913 - accuracy: 0.5336 - val_loss: 0.6902 - val_accuracy: 0.5125\n",
      "Epoch 19/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6914 - accuracy: 0.5211 - val_loss: 0.6876 - val_accuracy: 0.5719\n",
      "Epoch 20/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6872 - accuracy: 0.5383 - val_loss: 0.6832 - val_accuracy: 0.5500\n",
      "Epoch 21/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6875 - accuracy: 0.5289 - val_loss: 0.6881 - val_accuracy: 0.5406\n",
      "Epoch 22/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6901 - accuracy: 0.5234 - val_loss: 0.6849 - val_accuracy: 0.5750\n",
      "Epoch 23/60\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.6889 - accuracy: 0.5281 - val_loss: 0.6796 - val_accuracy: 0.5500\n",
      "Epoch 24/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6857 - accuracy: 0.5273 - val_loss: 0.6894 - val_accuracy: 0.5406\n",
      "Epoch 25/60\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.6908 - accuracy: 0.5297 - val_loss: 0.6807 - val_accuracy: 0.5469\n",
      "Epoch 26/60\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.6868 - accuracy: 0.5461 - val_loss: 0.6794 - val_accuracy: 0.5625\n",
      "Epoch 27/60\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.6856 - accuracy: 0.5453 - val_loss: 0.6807 - val_accuracy: 0.5375\n",
      "Epoch 28/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6860 - accuracy: 0.5508 - val_loss: 0.6823 - val_accuracy: 0.5219\n",
      "Epoch 29/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6808 - accuracy: 0.5344 - val_loss: 0.6856 - val_accuracy: 0.5250\n",
      "Epoch 30/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6825 - accuracy: 0.5523 - val_loss: 0.6898 - val_accuracy: 0.5469\n",
      "Epoch 31/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6793 - accuracy: 0.5641 - val_loss: 0.6830 - val_accuracy: 0.5281\n",
      "Epoch 32/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6852 - accuracy: 0.5484 - val_loss: 0.6845 - val_accuracy: 0.5156\n",
      "Epoch 33/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6766 - accuracy: 0.5406 - val_loss: 0.7023 - val_accuracy: 0.5094\n",
      "Epoch 34/60\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.6787 - accuracy: 0.5445 - val_loss: 0.6794 - val_accuracy: 0.5437\n",
      "Epoch 35/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6794 - accuracy: 0.5570 - val_loss: 0.6853 - val_accuracy: 0.5156\n",
      "Epoch 36/60\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.6802 - accuracy: 0.5484 - val_loss: 0.6773 - val_accuracy: 0.5344\n",
      "Epoch 37/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6809 - accuracy: 0.5570 - val_loss: 0.6818 - val_accuracy: 0.5469\n",
      "Epoch 38/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6743 - accuracy: 0.5508 - val_loss: 0.6789 - val_accuracy: 0.5500\n",
      "Epoch 39/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6681 - accuracy: 0.5539 - val_loss: 0.6797 - val_accuracy: 0.5344\n",
      "Epoch 40/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6701 - accuracy: 0.5758 - val_loss: 0.6771 - val_accuracy: 0.5344\n",
      "Epoch 41/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6702 - accuracy: 0.5836 - val_loss: 0.6730 - val_accuracy: 0.5344\n",
      "Epoch 42/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6703 - accuracy: 0.5719 - val_loss: 0.6741 - val_accuracy: 0.5281\n",
      "Epoch 43/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6671 - accuracy: 0.5820 - val_loss: 0.6732 - val_accuracy: 0.5437\n",
      "Epoch 44/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6592 - accuracy: 0.5898 - val_loss: 0.6712 - val_accuracy: 0.5469\n",
      "Epoch 45/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6676 - accuracy: 0.5758 - val_loss: 0.6710 - val_accuracy: 0.5406\n",
      "Epoch 46/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6568 - accuracy: 0.5813 - val_loss: 0.6738 - val_accuracy: 0.5312\n",
      "Epoch 47/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6552 - accuracy: 0.5977 - val_loss: 0.6807 - val_accuracy: 0.5406\n",
      "Epoch 48/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6579 - accuracy: 0.5797 - val_loss: 0.6658 - val_accuracy: 0.5344\n",
      "Epoch 49/60\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.6441 - accuracy: 0.6195 - val_loss: 0.6732 - val_accuracy: 0.5344\n",
      "Epoch 50/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6479 - accuracy: 0.6039 - val_loss: 0.6717 - val_accuracy: 0.5500\n",
      "Epoch 51/60\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.6411 - accuracy: 0.6156 - val_loss: 0.6647 - val_accuracy: 0.5562\n",
      "Epoch 52/60\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.6270 - accuracy: 0.6211 - val_loss: 0.6740 - val_accuracy: 0.5375\n",
      "Epoch 53/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6277 - accuracy: 0.6305 - val_loss: 0.6672 - val_accuracy: 0.5562\n",
      "Epoch 54/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6331 - accuracy: 0.6250 - val_loss: 0.6554 - val_accuracy: 0.6094\n",
      "Epoch 55/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6327 - accuracy: 0.6242 - val_loss: 0.6792 - val_accuracy: 0.5375\n",
      "Epoch 56/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6160 - accuracy: 0.6562 - val_loss: 0.6782 - val_accuracy: 0.5562\n",
      "Epoch 57/60\n",
      "40/40 [==============================] - 2s 37ms/step - loss: 0.6031 - accuracy: 0.6430 - val_loss: 0.6627 - val_accuracy: 0.5813\n",
      "Epoch 58/60\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.6036 - accuracy: 0.6422 - val_loss: 0.6694 - val_accuracy: 0.5750\n",
      "Epoch 59/60\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.5966 - accuracy: 0.6531 - val_loss: 0.6696 - val_accuracy: 0.5781\n",
      "Epoch 60/60\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.5920 - accuracy: 0.6766 - val_loss: 0.6544 - val_accuracy: 0.5969\n",
      "10/10 [==============================] - 1s 15ms/step\n",
      "Fold score (Accuracy score): 0.596875\n",
      "Matriz de confusion\n",
      "-------------------\n",
      "---------| Verdadero | Falso |\n",
      "Verdadero|  119        88\n",
      "Falso    |  41        72\n",
      "Fold #2\n",
      "Train - X:(1280, 40) y:(1280, 2)\n",
      "Test - X:(320, 40) y:(320, 2)\n",
      "Epoch 1/60\n",
      "40/40 [==============================] - 5s 63ms/step - loss: 0.6965 - accuracy: 0.5086 - val_loss: 0.6932 - val_accuracy: 0.4750\n",
      "Epoch 2/60\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.6947 - accuracy: 0.5008 - val_loss: 0.6924 - val_accuracy: 0.5250\n",
      "Epoch 3/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.6940 - accuracy: 0.5008 - val_loss: 0.6933 - val_accuracy: 0.4969\n",
      "Epoch 4/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6940 - accuracy: 0.5086 - val_loss: 0.6933 - val_accuracy: 0.4938\n",
      "Epoch 5/60\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.6918 - accuracy: 0.5289 - val_loss: 0.6952 - val_accuracy: 0.4875\n",
      "Epoch 6/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6931 - accuracy: 0.5156 - val_loss: 0.6954 - val_accuracy: 0.4594\n",
      "Epoch 7/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6925 - accuracy: 0.5180 - val_loss: 0.6950 - val_accuracy: 0.4500\n",
      "Epoch 8/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6927 - accuracy: 0.4922 - val_loss: 0.6946 - val_accuracy: 0.4812\n",
      "Epoch 9/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6915 - accuracy: 0.5078 - val_loss: 0.6951 - val_accuracy: 0.4688\n",
      "Epoch 10/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6935 - accuracy: 0.5055 - val_loss: 0.6941 - val_accuracy: 0.4875\n",
      "Epoch 11/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6924 - accuracy: 0.5047 - val_loss: 0.6928 - val_accuracy: 0.5063\n",
      "Epoch 12/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6896 - accuracy: 0.5188 - val_loss: 0.6940 - val_accuracy: 0.5125\n",
      "Epoch 13/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6905 - accuracy: 0.5266 - val_loss: 0.6914 - val_accuracy: 0.5250\n",
      "Epoch 14/60\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.6908 - accuracy: 0.5437 - val_loss: 0.6928 - val_accuracy: 0.5031\n",
      "Epoch 15/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6904 - accuracy: 0.5086 - val_loss: 0.6912 - val_accuracy: 0.5188\n",
      "Epoch 16/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6904 - accuracy: 0.5367 - val_loss: 0.6938 - val_accuracy: 0.5125\n",
      "Epoch 17/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6913 - accuracy: 0.5203 - val_loss: 0.6910 - val_accuracy: 0.5344\n",
      "Epoch 18/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6880 - accuracy: 0.5461 - val_loss: 0.6877 - val_accuracy: 0.5250\n",
      "Epoch 19/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6903 - accuracy: 0.5266 - val_loss: 0.6876 - val_accuracy: 0.5469\n",
      "Epoch 20/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6884 - accuracy: 0.5211 - val_loss: 0.6898 - val_accuracy: 0.5500\n",
      "Epoch 21/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6896 - accuracy: 0.5281 - val_loss: 0.6854 - val_accuracy: 0.5469\n",
      "Epoch 22/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6853 - accuracy: 0.5422 - val_loss: 0.6861 - val_accuracy: 0.5281\n",
      "Epoch 23/60\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.6846 - accuracy: 0.5477 - val_loss: 0.6908 - val_accuracy: 0.5312\n",
      "Epoch 24/60\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.6867 - accuracy: 0.5281 - val_loss: 0.6914 - val_accuracy: 0.5469\n",
      "Epoch 25/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6863 - accuracy: 0.5172 - val_loss: 0.6833 - val_accuracy: 0.5312\n",
      "Epoch 26/60\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.6846 - accuracy: 0.5297 - val_loss: 0.6842 - val_accuracy: 0.5125\n",
      "Epoch 27/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6849 - accuracy: 0.5289 - val_loss: 0.6828 - val_accuracy: 0.5250\n",
      "Epoch 28/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6866 - accuracy: 0.5227 - val_loss: 0.6905 - val_accuracy: 0.5219\n",
      "Epoch 29/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6864 - accuracy: 0.5211 - val_loss: 0.6865 - val_accuracy: 0.5156\n",
      "Epoch 30/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6810 - accuracy: 0.5219 - val_loss: 0.6852 - val_accuracy: 0.5281\n",
      "Epoch 31/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6781 - accuracy: 0.5328 - val_loss: 0.6868 - val_accuracy: 0.5063\n",
      "Epoch 32/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6777 - accuracy: 0.5430 - val_loss: 0.6805 - val_accuracy: 0.5437\n",
      "Epoch 33/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6747 - accuracy: 0.5437 - val_loss: 0.6799 - val_accuracy: 0.5125\n",
      "Epoch 34/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6784 - accuracy: 0.5359 - val_loss: 0.6914 - val_accuracy: 0.5219\n",
      "Epoch 35/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6732 - accuracy: 0.5500 - val_loss: 0.6752 - val_accuracy: 0.5562\n",
      "Epoch 36/60\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.6691 - accuracy: 0.5648 - val_loss: 0.6810 - val_accuracy: 0.5375\n",
      "Epoch 37/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6832 - accuracy: 0.5406 - val_loss: 0.6832 - val_accuracy: 0.5469\n",
      "Epoch 38/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6796 - accuracy: 0.5469 - val_loss: 0.6710 - val_accuracy: 0.5656\n",
      "Epoch 39/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6673 - accuracy: 0.5648 - val_loss: 0.6730 - val_accuracy: 0.5719\n",
      "Epoch 40/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6725 - accuracy: 0.5625 - val_loss: 0.6729 - val_accuracy: 0.5469\n",
      "Epoch 41/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6622 - accuracy: 0.5461 - val_loss: 0.6638 - val_accuracy: 0.5656\n",
      "Epoch 42/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6629 - accuracy: 0.5633 - val_loss: 0.6660 - val_accuracy: 0.5750\n",
      "Epoch 43/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6656 - accuracy: 0.5672 - val_loss: 0.6794 - val_accuracy: 0.5594\n",
      "Epoch 44/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6680 - accuracy: 0.5789 - val_loss: 0.6810 - val_accuracy: 0.5719\n",
      "Epoch 45/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6641 - accuracy: 0.5602 - val_loss: 0.6824 - val_accuracy: 0.5375\n",
      "Epoch 46/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6659 - accuracy: 0.5797 - val_loss: 0.6652 - val_accuracy: 0.5594\n",
      "Epoch 47/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6630 - accuracy: 0.5594 - val_loss: 0.6625 - val_accuracy: 0.5938\n",
      "Epoch 48/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6521 - accuracy: 0.5805 - val_loss: 0.6606 - val_accuracy: 0.5781\n",
      "Epoch 49/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6502 - accuracy: 0.5820 - val_loss: 0.6522 - val_accuracy: 0.5688\n",
      "Epoch 50/60\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.6541 - accuracy: 0.5727 - val_loss: 0.6699 - val_accuracy: 0.5500\n",
      "Epoch 51/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6548 - accuracy: 0.5758 - val_loss: 0.6587 - val_accuracy: 0.5688\n",
      "Epoch 52/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6424 - accuracy: 0.5672 - val_loss: 0.6629 - val_accuracy: 0.5188\n",
      "Epoch 53/60\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.6432 - accuracy: 0.5773 - val_loss: 0.6522 - val_accuracy: 0.5906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6452 - accuracy: 0.5844 - val_loss: 0.6437 - val_accuracy: 0.5875\n",
      "Epoch 55/60\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.6379 - accuracy: 0.5828 - val_loss: 0.6430 - val_accuracy: 0.5750\n",
      "Epoch 56/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6358 - accuracy: 0.5930 - val_loss: 0.6613 - val_accuracy: 0.5625\n",
      "Epoch 57/60\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.6560 - accuracy: 0.5664 - val_loss: 0.6647 - val_accuracy: 0.5781\n",
      "Epoch 58/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6399 - accuracy: 0.5859 - val_loss: 0.6513 - val_accuracy: 0.5906\n",
      "Epoch 59/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6338 - accuracy: 0.5977 - val_loss: 0.6422 - val_accuracy: 0.5906\n",
      "Epoch 60/60\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.6225 - accuracy: 0.6148 - val_loss: 0.6642 - val_accuracy: 0.5656\n",
      "10/10 [==============================] - 1s 17ms/step\n",
      "Fold score (Accuracy score): 0.565625\n",
      "Matriz de confusion\n",
      "-------------------\n",
      "---------| Verdadero | Falso |\n",
      "Verdadero|  111        82\n",
      "Falso    |  57        70\n",
      "Fold #3\n",
      "Train - X:(1280, 40) y:(1280, 2)\n",
      "Test - X:(320, 40) y:(320, 2)\n",
      "Epoch 1/60\n",
      "40/40 [==============================] - 4s 55ms/step - loss: 0.6965 - accuracy: 0.5070 - val_loss: 0.6961 - val_accuracy: 0.4875\n",
      "Epoch 2/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6936 - accuracy: 0.5133 - val_loss: 0.6929 - val_accuracy: 0.4969\n",
      "Epoch 3/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6963 - accuracy: 0.4891 - val_loss: 0.6931 - val_accuracy: 0.4969\n",
      "Epoch 4/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6930 - accuracy: 0.5094 - val_loss: 0.6954 - val_accuracy: 0.4656\n",
      "Epoch 5/60\n",
      "40/40 [==============================] - 2s 37ms/step - loss: 0.6926 - accuracy: 0.5148 - val_loss: 0.6965 - val_accuracy: 0.4594\n",
      "Epoch 6/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6906 - accuracy: 0.5297 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 7/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6926 - accuracy: 0.5281 - val_loss: 0.6984 - val_accuracy: 0.4406\n",
      "Epoch 8/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6887 - accuracy: 0.5406 - val_loss: 0.6953 - val_accuracy: 0.5000\n",
      "Epoch 9/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6860 - accuracy: 0.5461 - val_loss: 0.6988 - val_accuracy: 0.4563\n",
      "Epoch 10/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6884 - accuracy: 0.5305 - val_loss: 0.6955 - val_accuracy: 0.5063\n",
      "Epoch 11/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6873 - accuracy: 0.5336 - val_loss: 0.6983 - val_accuracy: 0.4688\n",
      "Epoch 12/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6874 - accuracy: 0.5273 - val_loss: 0.6921 - val_accuracy: 0.5063\n",
      "Epoch 13/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6903 - accuracy: 0.5211 - val_loss: 0.6921 - val_accuracy: 0.5031\n",
      "Epoch 14/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6821 - accuracy: 0.5500 - val_loss: 0.7003 - val_accuracy: 0.5000\n",
      "Epoch 15/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6849 - accuracy: 0.5367 - val_loss: 0.6912 - val_accuracy: 0.4938\n",
      "Epoch 16/60\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.6825 - accuracy: 0.5516 - val_loss: 0.6900 - val_accuracy: 0.5344\n",
      "Epoch 17/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6796 - accuracy: 0.5547 - val_loss: 0.7032 - val_accuracy: 0.4781\n",
      "Epoch 18/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6832 - accuracy: 0.5359 - val_loss: 0.6974 - val_accuracy: 0.4875\n",
      "Epoch 19/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6859 - accuracy: 0.5375 - val_loss: 0.6909 - val_accuracy: 0.4781\n",
      "Epoch 20/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6775 - accuracy: 0.5562 - val_loss: 0.6889 - val_accuracy: 0.4969\n",
      "Epoch 21/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6756 - accuracy: 0.5734 - val_loss: 0.6873 - val_accuracy: 0.4969\n",
      "Epoch 22/60\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.6739 - accuracy: 0.5430 - val_loss: 0.6905 - val_accuracy: 0.4875\n",
      "Epoch 23/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6743 - accuracy: 0.5469 - val_loss: 0.6938 - val_accuracy: 0.5156\n",
      "Epoch 24/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6749 - accuracy: 0.5680 - val_loss: 0.6991 - val_accuracy: 0.4969\n",
      "Epoch 25/60\n",
      "40/40 [==============================] - 2s 37ms/step - loss: 0.6766 - accuracy: 0.5602 - val_loss: 0.6816 - val_accuracy: 0.5156\n",
      "Epoch 26/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6689 - accuracy: 0.5672 - val_loss: 0.6854 - val_accuracy: 0.4938\n",
      "Epoch 27/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6639 - accuracy: 0.5789 - val_loss: 0.6867 - val_accuracy: 0.5000\n",
      "Epoch 28/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6677 - accuracy: 0.5570 - val_loss: 0.6904 - val_accuracy: 0.5063\n",
      "Epoch 29/60\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.6649 - accuracy: 0.5781 - val_loss: 0.6794 - val_accuracy: 0.5156\n",
      "Epoch 30/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6574 - accuracy: 0.5938 - val_loss: 0.6771 - val_accuracy: 0.5531\n",
      "Epoch 31/60\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.6584 - accuracy: 0.5641 - val_loss: 0.6764 - val_accuracy: 0.5344\n",
      "Epoch 32/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6521 - accuracy: 0.5891 - val_loss: 0.6698 - val_accuracy: 0.5531\n",
      "Epoch 33/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6503 - accuracy: 0.5789 - val_loss: 0.6591 - val_accuracy: 0.5656\n",
      "Epoch 34/60\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.6461 - accuracy: 0.6039 - val_loss: 0.6705 - val_accuracy: 0.5437\n",
      "Epoch 35/60\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.6407 - accuracy: 0.6000 - val_loss: 0.6866 - val_accuracy: 0.5406\n",
      "Epoch 36/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6438 - accuracy: 0.5992 - val_loss: 0.6703 - val_accuracy: 0.5562\n",
      "Epoch 37/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6353 - accuracy: 0.5930 - val_loss: 0.6809 - val_accuracy: 0.5344\n",
      "Epoch 38/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6425 - accuracy: 0.6008 - val_loss: 0.6711 - val_accuracy: 0.5813\n",
      "Epoch 39/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6324 - accuracy: 0.6086 - val_loss: 0.6642 - val_accuracy: 0.5469\n",
      "Epoch 40/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.6238 - accuracy: 0.6078 - val_loss: 0.6714 - val_accuracy: 0.5875\n",
      "Epoch 41/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.6208 - accuracy: 0.6258 - val_loss: 0.6519 - val_accuracy: 0.5781\n",
      "Epoch 42/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6219 - accuracy: 0.6117 - val_loss: 0.6702 - val_accuracy: 0.5688\n",
      "Epoch 43/60\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.6114 - accuracy: 0.6187 - val_loss: 0.6657 - val_accuracy: 0.5750\n",
      "Epoch 44/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6026 - accuracy: 0.6281 - val_loss: 0.6613 - val_accuracy: 0.5906\n",
      "Epoch 45/60\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.5903 - accuracy: 0.6430 - val_loss: 0.6580 - val_accuracy: 0.5969\n",
      "Epoch 46/60\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.6252 - accuracy: 0.6234 - val_loss: 0.6452 - val_accuracy: 0.5906\n",
      "Epoch 47/60\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.6048 - accuracy: 0.6273 - val_loss: 0.6544 - val_accuracy: 0.6062\n",
      "Epoch 48/60\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.5879 - accuracy: 0.6531 - val_loss: 0.6628 - val_accuracy: 0.5906\n",
      "Epoch 49/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.5794 - accuracy: 0.6617 - val_loss: 0.6840 - val_accuracy: 0.5906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.5779 - accuracy: 0.6664 - val_loss: 0.6463 - val_accuracy: 0.6313\n",
      "Epoch 51/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.5846 - accuracy: 0.6508 - val_loss: 0.6481 - val_accuracy: 0.6062\n",
      "Epoch 52/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.5632 - accuracy: 0.6687 - val_loss: 0.6533 - val_accuracy: 0.6344\n",
      "Epoch 53/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.5631 - accuracy: 0.6812 - val_loss: 0.6545 - val_accuracy: 0.6219\n",
      "Epoch 54/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.5494 - accuracy: 0.6867 - val_loss: 0.6615 - val_accuracy: 0.6156\n",
      "Epoch 55/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.5571 - accuracy: 0.6586 - val_loss: 0.6411 - val_accuracy: 0.6469\n",
      "Epoch 56/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.5574 - accuracy: 0.6781 - val_loss: 0.6319 - val_accuracy: 0.6469\n",
      "Epoch 57/60\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.5463 - accuracy: 0.6703 - val_loss: 0.6474 - val_accuracy: 0.5969\n",
      "Epoch 58/60\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.5302 - accuracy: 0.6781 - val_loss: 0.6272 - val_accuracy: 0.6469\n",
      "Epoch 59/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.5117 - accuracy: 0.7078 - val_loss: 0.6410 - val_accuracy: 0.6562\n",
      "Epoch 60/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.5090 - accuracy: 0.7109 - val_loss: 0.6077 - val_accuracy: 0.6625\n",
      "10/10 [==============================] - 1s 16ms/step\n",
      "Fold score (Accuracy score): 0.6625\n",
      "Matriz de confusion\n",
      "-------------------\n",
      "---------| Verdadero | Falso |\n",
      "Verdadero|  122        73\n",
      "Falso    |  35        90\n",
      "Fold #4\n",
      "Train - X:(1280, 40) y:(1280, 2)\n",
      "Test - X:(320, 40) y:(320, 2)\n",
      "Epoch 1/60\n",
      "40/40 [==============================] - 4s 56ms/step - loss: 0.7007 - accuracy: 0.4609 - val_loss: 0.6932 - val_accuracy: 0.5156\n",
      "Epoch 2/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6962 - accuracy: 0.4883 - val_loss: 0.6930 - val_accuracy: 0.4938\n",
      "Epoch 3/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6949 - accuracy: 0.4992 - val_loss: 0.6920 - val_accuracy: 0.4938\n",
      "Epoch 4/60\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.6936 - accuracy: 0.5102 - val_loss: 0.6922 - val_accuracy: 0.5094\n",
      "Epoch 5/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6949 - accuracy: 0.5000 - val_loss: 0.6928 - val_accuracy: 0.5063\n",
      "Epoch 6/60\n",
      "40/40 [==============================] - 2s 37ms/step - loss: 0.6919 - accuracy: 0.5211 - val_loss: 0.6918 - val_accuracy: 0.5188\n",
      "Epoch 7/60\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.6950 - accuracy: 0.5102 - val_loss: 0.6916 - val_accuracy: 0.5375\n",
      "Epoch 8/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6926 - accuracy: 0.5148 - val_loss: 0.6924 - val_accuracy: 0.5312\n",
      "Epoch 9/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6921 - accuracy: 0.5195 - val_loss: 0.6915 - val_accuracy: 0.5469\n",
      "Epoch 10/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6918 - accuracy: 0.5195 - val_loss: 0.6924 - val_accuracy: 0.5281\n",
      "Epoch 11/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6919 - accuracy: 0.5336 - val_loss: 0.6920 - val_accuracy: 0.5375\n",
      "Epoch 12/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6898 - accuracy: 0.5266 - val_loss: 0.6922 - val_accuracy: 0.5000\n",
      "Epoch 13/60\n",
      "40/40 [==============================] - 2s 37ms/step - loss: 0.6924 - accuracy: 0.5141 - val_loss: 0.6906 - val_accuracy: 0.5500\n",
      "Epoch 14/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6894 - accuracy: 0.5234 - val_loss: 0.6916 - val_accuracy: 0.5250\n",
      "Epoch 15/60\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.6890 - accuracy: 0.5227 - val_loss: 0.6930 - val_accuracy: 0.5063\n",
      "Epoch 16/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6914 - accuracy: 0.5336 - val_loss: 0.6893 - val_accuracy: 0.5437\n",
      "Epoch 17/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6900 - accuracy: 0.5297 - val_loss: 0.6893 - val_accuracy: 0.5000\n",
      "Epoch 18/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6851 - accuracy: 0.5430 - val_loss: 0.6959 - val_accuracy: 0.5031\n",
      "Epoch 19/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6841 - accuracy: 0.5312 - val_loss: 0.6896 - val_accuracy: 0.5219\n",
      "Epoch 20/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6846 - accuracy: 0.5305 - val_loss: 0.6880 - val_accuracy: 0.5188\n",
      "Epoch 21/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6830 - accuracy: 0.5477 - val_loss: 0.6917 - val_accuracy: 0.5375\n",
      "Epoch 22/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6843 - accuracy: 0.5508 - val_loss: 0.6887 - val_accuracy: 0.5406\n",
      "Epoch 23/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6881 - accuracy: 0.5359 - val_loss: 0.6876 - val_accuracy: 0.5625\n",
      "Epoch 24/60\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.6847 - accuracy: 0.5406 - val_loss: 0.6846 - val_accuracy: 0.5406\n",
      "Epoch 25/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6812 - accuracy: 0.5516 - val_loss: 0.6891 - val_accuracy: 0.5406\n",
      "Epoch 26/60\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.6774 - accuracy: 0.5531 - val_loss: 0.6852 - val_accuracy: 0.5531\n",
      "Epoch 27/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6799 - accuracy: 0.5633 - val_loss: 0.6786 - val_accuracy: 0.5844\n",
      "Epoch 28/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6758 - accuracy: 0.5422 - val_loss: 0.6884 - val_accuracy: 0.5250\n",
      "Epoch 29/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6795 - accuracy: 0.5406 - val_loss: 0.6776 - val_accuracy: 0.5281\n",
      "Epoch 30/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6735 - accuracy: 0.5609 - val_loss: 0.6750 - val_accuracy: 0.5594\n",
      "Epoch 31/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6696 - accuracy: 0.5664 - val_loss: 0.6799 - val_accuracy: 0.5063\n",
      "Epoch 32/60\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.6708 - accuracy: 0.5648 - val_loss: 0.6859 - val_accuracy: 0.5375\n",
      "Epoch 33/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6724 - accuracy: 0.5828 - val_loss: 0.6774 - val_accuracy: 0.5531\n",
      "Epoch 34/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6739 - accuracy: 0.5695 - val_loss: 0.6910 - val_accuracy: 0.5312\n",
      "Epoch 35/60\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.6664 - accuracy: 0.5680 - val_loss: 0.6716 - val_accuracy: 0.5406\n",
      "Epoch 36/60\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.6630 - accuracy: 0.5766 - val_loss: 0.6784 - val_accuracy: 0.5344\n",
      "Epoch 37/60\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.6594 - accuracy: 0.5688 - val_loss: 0.6689 - val_accuracy: 0.5500\n",
      "Epoch 38/60\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.6571 - accuracy: 0.5867 - val_loss: 0.6730 - val_accuracy: 0.5031\n",
      "Epoch 39/60\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.6581 - accuracy: 0.5711 - val_loss: 0.6579 - val_accuracy: 0.5500\n",
      "Epoch 40/60\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.6486 - accuracy: 0.6102 - val_loss: 0.6652 - val_accuracy: 0.5844\n",
      "Epoch 41/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6516 - accuracy: 0.6102 - val_loss: 0.6676 - val_accuracy: 0.5938\n",
      "Epoch 42/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6486 - accuracy: 0.6008 - val_loss: 0.6636 - val_accuracy: 0.5813\n",
      "Epoch 43/60\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.6419 - accuracy: 0.6133 - val_loss: 0.6643 - val_accuracy: 0.5875\n",
      "Epoch 44/60\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.6321 - accuracy: 0.6195 - val_loss: 0.6577 - val_accuracy: 0.5750\n",
      "Epoch 45/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6123 - accuracy: 0.6484 - val_loss: 0.6664 - val_accuracy: 0.5719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/60\n",
      "40/40 [==============================] - 1s 36ms/step - loss: 0.6359 - accuracy: 0.6031 - val_loss: 0.6476 - val_accuracy: 0.6031\n",
      "Epoch 47/60\n",
      "40/40 [==============================] - 1s 35ms/step - loss: 0.6154 - accuracy: 0.6297 - val_loss: 0.6502 - val_accuracy: 0.5781\n",
      "Epoch 48/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.6113 - accuracy: 0.6430 - val_loss: 0.6458 - val_accuracy: 0.6125\n",
      "Epoch 49/60\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.6028 - accuracy: 0.6445 - val_loss: 0.6408 - val_accuracy: 0.5844\n",
      "Epoch 50/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.6002 - accuracy: 0.6602 - val_loss: 0.6551 - val_accuracy: 0.5813\n",
      "Epoch 51/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.5992 - accuracy: 0.6438 - val_loss: 0.6745 - val_accuracy: 0.5844\n",
      "Epoch 52/60\n",
      "40/40 [==============================] - 2s 40ms/step - loss: 0.5658 - accuracy: 0.6859 - val_loss: 0.6742 - val_accuracy: 0.6187\n",
      "Epoch 53/60\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.5758 - accuracy: 0.6859 - val_loss: 0.6059 - val_accuracy: 0.6531\n",
      "Epoch 54/60\n",
      "40/40 [==============================] - 2s 37ms/step - loss: 0.5480 - accuracy: 0.6875 - val_loss: 0.6202 - val_accuracy: 0.6375\n",
      "Epoch 55/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.5306 - accuracy: 0.7195 - val_loss: 0.6449 - val_accuracy: 0.6344\n",
      "Epoch 56/60\n",
      "40/40 [==============================] - 2s 39ms/step - loss: 0.5384 - accuracy: 0.7148 - val_loss: 0.6178 - val_accuracy: 0.6281\n",
      "Epoch 57/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.5031 - accuracy: 0.7445 - val_loss: 0.6330 - val_accuracy: 0.6531\n",
      "Epoch 58/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.4944 - accuracy: 0.7367 - val_loss: 0.6327 - val_accuracy: 0.6812\n",
      "Epoch 59/60\n",
      "40/40 [==============================] - 1s 37ms/step - loss: 0.5028 - accuracy: 0.7305 - val_loss: 0.6287 - val_accuracy: 0.6531\n",
      "Epoch 60/60\n",
      "40/40 [==============================] - 2s 38ms/step - loss: 0.5037 - accuracy: 0.7477 - val_loss: 0.5791 - val_accuracy: 0.7000\n",
      "10/10 [==============================] - 1s 14ms/step\n",
      "Fold score (Accuracy score): 0.7\n",
      "Matriz de confusion\n",
      "-------------------\n",
      "---------| Verdadero | Falso |\n",
      "Verdadero|  112        46\n",
      "Falso    |  50        112\n",
      "Fold #5\n",
      "Train - X:(1280, 40) y:(1280, 2)\n",
      "Test - X:(320, 40) y:(320, 2)\n",
      "Epoch 1/60\n",
      "40/40 [==============================] - 5s 68ms/step - loss: 0.6964 - accuracy: 0.4938 - val_loss: 0.6906 - val_accuracy: 0.5594\n",
      "Epoch 2/60\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.6969 - accuracy: 0.4727 - val_loss: 0.6928 - val_accuracy: 0.5344\n",
      "Epoch 3/60\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.6925 - accuracy: 0.5297 - val_loss: 0.6956 - val_accuracy: 0.4656\n",
      "Epoch 4/60\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.6933 - accuracy: 0.5102 - val_loss: 0.6932 - val_accuracy: 0.5063\n",
      "Epoch 5/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6932 - accuracy: 0.4953 - val_loss: 0.6904 - val_accuracy: 0.5188\n",
      "Epoch 6/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.6916 - accuracy: 0.5086 - val_loss: 0.6982 - val_accuracy: 0.4375\n",
      "Epoch 7/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6899 - accuracy: 0.5344 - val_loss: 0.7059 - val_accuracy: 0.4688\n",
      "Epoch 8/60\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.6929 - accuracy: 0.5281 - val_loss: 0.6952 - val_accuracy: 0.5094\n",
      "Epoch 9/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.6884 - accuracy: 0.5289 - val_loss: 0.6888 - val_accuracy: 0.5469\n",
      "Epoch 10/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.6880 - accuracy: 0.5375 - val_loss: 0.6885 - val_accuracy: 0.5312\n",
      "Epoch 11/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6915 - accuracy: 0.5086 - val_loss: 0.6908 - val_accuracy: 0.4969\n",
      "Epoch 12/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.6849 - accuracy: 0.5484 - val_loss: 0.6897 - val_accuracy: 0.5344\n",
      "Epoch 13/60\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.6848 - accuracy: 0.5344 - val_loss: 0.6886 - val_accuracy: 0.5250\n",
      "Epoch 14/60\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.6818 - accuracy: 0.5398 - val_loss: 0.7000 - val_accuracy: 0.5094\n",
      "Epoch 15/60\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.6828 - accuracy: 0.5469 - val_loss: 0.6925 - val_accuracy: 0.5125\n",
      "Epoch 16/60\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.6825 - accuracy: 0.5453 - val_loss: 0.7042 - val_accuracy: 0.5156\n",
      "Epoch 17/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.6816 - accuracy: 0.5555 - val_loss: 0.7013 - val_accuracy: 0.5031\n",
      "Epoch 18/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6798 - accuracy: 0.5484 - val_loss: 0.6949 - val_accuracy: 0.5156\n",
      "Epoch 19/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6749 - accuracy: 0.5547 - val_loss: 0.6826 - val_accuracy: 0.5813\n",
      "Epoch 20/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6740 - accuracy: 0.5813 - val_loss: 0.6730 - val_accuracy: 0.5625\n",
      "Epoch 21/60\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.6713 - accuracy: 0.5859 - val_loss: 0.6816 - val_accuracy: 0.5469\n",
      "Epoch 22/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.6752 - accuracy: 0.5719 - val_loss: 0.6928 - val_accuracy: 0.5250\n",
      "Epoch 23/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.6727 - accuracy: 0.5641 - val_loss: 0.6696 - val_accuracy: 0.5094\n",
      "Epoch 24/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.6719 - accuracy: 0.5820 - val_loss: 0.6866 - val_accuracy: 0.5312\n",
      "Epoch 25/60\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.6664 - accuracy: 0.5797 - val_loss: 0.6856 - val_accuracy: 0.5125\n",
      "Epoch 26/60\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.6649 - accuracy: 0.5766 - val_loss: 0.6984 - val_accuracy: 0.5437\n",
      "Epoch 27/60\n",
      "40/40 [==============================] - 2s 58ms/step - loss: 0.6636 - accuracy: 0.5844 - val_loss: 0.6790 - val_accuracy: 0.5656\n",
      "Epoch 28/60\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.6581 - accuracy: 0.6008 - val_loss: 0.6993 - val_accuracy: 0.5250\n",
      "Epoch 29/60\n",
      "40/40 [==============================] - 2s 54ms/step - loss: 0.6707 - accuracy: 0.5703 - val_loss: 0.6808 - val_accuracy: 0.5531\n",
      "Epoch 30/60\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6574 - accuracy: 0.5852 - val_loss: 0.6791 - val_accuracy: 0.5281\n",
      "Epoch 31/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.6501 - accuracy: 0.5961 - val_loss: 0.6909 - val_accuracy: 0.5281\n",
      "Epoch 32/60\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.6541 - accuracy: 0.5930 - val_loss: 0.6823 - val_accuracy: 0.5406\n",
      "Epoch 33/60\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.6469 - accuracy: 0.6180 - val_loss: 0.6970 - val_accuracy: 0.5312\n",
      "Epoch 34/60\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.6418 - accuracy: 0.6062 - val_loss: 0.6795 - val_accuracy: 0.5500\n",
      "Epoch 35/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6348 - accuracy: 0.6195 - val_loss: 0.6695 - val_accuracy: 0.5594\n",
      "Epoch 36/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6395 - accuracy: 0.6148 - val_loss: 0.6887 - val_accuracy: 0.5375\n",
      "Epoch 37/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6378 - accuracy: 0.6180 - val_loss: 0.6851 - val_accuracy: 0.5594\n",
      "Epoch 38/60\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.6312 - accuracy: 0.6336 - val_loss: 0.6763 - val_accuracy: 0.5625\n",
      "Epoch 39/60\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.6191 - accuracy: 0.6406 - val_loss: 0.6715 - val_accuracy: 0.5625\n",
      "Epoch 40/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.6199 - accuracy: 0.6328 - val_loss: 0.6778 - val_accuracy: 0.5750\n",
      "Epoch 41/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.6119 - accuracy: 0.6297 - val_loss: 0.6654 - val_accuracy: 0.5500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.6130 - accuracy: 0.6336 - val_loss: 0.6939 - val_accuracy: 0.5437\n",
      "Epoch 43/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.6020 - accuracy: 0.6539 - val_loss: 0.6654 - val_accuracy: 0.5938\n",
      "Epoch 44/60\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.5870 - accuracy: 0.6562 - val_loss: 0.6447 - val_accuracy: 0.6125\n",
      "Epoch 45/60\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.5851 - accuracy: 0.6750 - val_loss: 0.6623 - val_accuracy: 0.6375\n",
      "Epoch 46/60\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.5727 - accuracy: 0.6742 - val_loss: 0.6434 - val_accuracy: 0.6250\n",
      "Epoch 47/60\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.5718 - accuracy: 0.6773 - val_loss: 0.6584 - val_accuracy: 0.5844\n",
      "Epoch 48/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.5639 - accuracy: 0.6773 - val_loss: 0.6474 - val_accuracy: 0.6313\n",
      "Epoch 49/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.5396 - accuracy: 0.7031 - val_loss: 0.6731 - val_accuracy: 0.5875\n",
      "Epoch 50/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.5411 - accuracy: 0.6969 - val_loss: 0.6331 - val_accuracy: 0.6406\n",
      "Epoch 51/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.5302 - accuracy: 0.7125 - val_loss: 0.6174 - val_accuracy: 0.6719\n",
      "Epoch 52/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.5129 - accuracy: 0.7141 - val_loss: 0.6191 - val_accuracy: 0.6781\n",
      "Epoch 53/60\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.5258 - accuracy: 0.7156 - val_loss: 0.6458 - val_accuracy: 0.6750\n",
      "Epoch 54/60\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.5175 - accuracy: 0.7258 - val_loss: 0.5981 - val_accuracy: 0.6469\n",
      "Epoch 55/60\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.4953 - accuracy: 0.7375 - val_loss: 0.6078 - val_accuracy: 0.7094\n",
      "Epoch 56/60\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.4808 - accuracy: 0.7516 - val_loss: 0.5857 - val_accuracy: 0.6906\n",
      "Epoch 57/60\n",
      "40/40 [==============================] - 2s 50ms/step - loss: 0.4920 - accuracy: 0.7328 - val_loss: 0.6250 - val_accuracy: 0.7031\n",
      "Epoch 58/60\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.4837 - accuracy: 0.7656 - val_loss: 0.6406 - val_accuracy: 0.6531\n",
      "Epoch 59/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.4726 - accuracy: 0.7578 - val_loss: 0.6479 - val_accuracy: 0.6719\n",
      "Epoch 60/60\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.4622 - accuracy: 0.7641 - val_loss: 0.6832 - val_accuracy: 0.6344\n",
      "10/10 [==============================] - 1s 20ms/step\n",
      "Fold score (Accuracy score): 0.634375\n",
      "Matriz de confusion\n",
      "-------------------\n",
      "---------| Verdadero | Falso |\n",
      "Verdadero|  83        47\n",
      "Falso    |  70        120\n",
      "-----------------------\n",
      "Cross-validated score (Accuracy score): 0.631875\n",
      "-----------------------\n",
      "Resumen\n",
      "Fold score (Accuracy score): 0.596875\n",
      "Fold score (Accuracy score): 0.565625\n",
      "Fold score (Accuracy score): 0.6625\n",
      "Fold score (Accuracy score): 0.7\n",
      "Fold score (Accuracy score): 0.634375\n"
     ]
    }
   ],
   "source": [
    "k_fold = KFold(5)\n",
    "fold = 0\n",
    "y_tests = []\n",
    "predictions = []\n",
    "scores = []\n",
    "X = np.concatenate((X_train, X_test))\n",
    "y = np.concatenate((y_train, y_test))\n",
    "for train, test in k_fold.split(X):\n",
    "    fold = fold + 1\n",
    "    print(f\"Fold #{fold}\")\n",
    "    X_train = X[train]\n",
    "    X_test = X[test]\n",
    "    y_train = y[train]\n",
    "    y_test = y[test]\n",
    "    print(f\"Train - X:{X_train.shape} y:{y_train.shape}\")\n",
    "    print(f\"Test - X:{X_test.shape} y:{y_test.shape}\")\n",
    "    \n",
    "    num_labels = y.shape[1]\n",
    "    dim_entrada = (X_train.shape[1],1)\n",
    "\n",
    "    #model = new_RNN()\n",
    "    model = new_RNN()\n",
    "    callbacks = []\n",
    "    '''\n",
    "    callbacks = [\n",
    "    EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            min_delta=1e-2,\n",
    "            patience=20,\n",
    "            verbose=1,\n",
    "        )\n",
    "    ]\n",
    "    '''\n",
    "    num_epochs = 60\n",
    "    num_batch_size = 32\n",
    "    start = datetime.datetime.now()\n",
    "   \n",
    "    results = model.fit(X_train, y_train, batch_size=num_batch_size,epochs=num_epochs, validation_data=(X_test, y_test),callbacks=callbacks)\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    y_tests.append(y_test)\n",
    "    pred=[([1,0] if i[0]>i[1] else [0,1]) for i in pred]\n",
    "    predictions.append(pred)\n",
    "    score = metrics.accuracy_score(pred, y_test)\n",
    "    math = confusion_matrix([(1 if x[0]==1 else 0) for x in pred],[(1 if x[0]==1 else 0) for x in y_test], labels=[1,0])\n",
    "    scores.append([score])\n",
    "    print(f\"Fold score (Accuracy score): {score}\")\n",
    "    print(\"Matriz de confusion\")\n",
    "    print(\"-------------------\")\n",
    "    print(\"---------| Verdadero | Falso |\")\n",
    "    print(f\"Verdadero|  {math[0][0]}        {math[0][1]}\")\n",
    "    print(f\"Falso    |  {math[1][0]}        {math[1][1]}\")\n",
    "\n",
    "y_tests = np.concatenate(y_tests)\n",
    "predictions = np.concatenate(predictions)\n",
    "score = metrics.accuracy_score(predictions, y_tests)\n",
    "print(\"-----------------------\")\n",
    "print(f\"Cross-validated score (Accuracy score): {score}\")\n",
    "print(\"-----------------------\")\n",
    "print(\"Resumen\")\n",
    "for result in scores:\n",
    "    print(f\"Fold score (Accuracy score): {result[0]}\")\n",
    "    \n",
    "#https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_05_2_kfold.ipynb\n",
    "#https://www.youtube.com/watch?v=maiQf8ray_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb0e73ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_range, training_loss, 'r',marker=\"o\",linestyle=\"--\")\n",
    "plt.plot(epochs_range, test_loss, 'b',marker=\"o\",linestyle=\"-\")\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.rcParams[\"figure.figsize\"] = (20,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d79330e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.7190426588058472 val_accuracy: 0.71875\n",
      "El algoritmo acerto 230 veces sobre los 320 casos.\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"val_loss: {test_accuracy[0]}\", f\"val_accuracy: {test_accuracy[1]}\")\n",
    "\n",
    "y_i = len(y_values)\n",
    "i = 0\n",
    "true_values = 0\n",
    "while (i < y_i):\n",
    "    true_values += (1 if (y_test[i][0] == y_prediction[i][0] or y_test[i][1] == y_prediction[i][1]) else 0)\n",
    "    i = i + 1 \n",
    "    \n",
    "print(f\"El algoritmo acerto {true_values} veces sobre los {y_i} casos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bad97191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCross-validated score (Accuracy score): 0.8200663349917081\\n-----------------------\\nResumen\\nFold score (Accuracy score): 0.8281573498964804\\nFold score (Accuracy score): 0.8Detector de la mentira usando redes neuronales recurrentes426501035196687\\nFold score (Accuracy score): 0.8008298755186722\\nFold score (Accuracy score): 0.8174273858921162\\nFold score (Accuracy score): 0.8112033195020747\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def new_RNN():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50,input_shape= dim_entrada, return_sequences=False))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f0a73",
   "metadata": {},
   "source": [
    "#### Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9995db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:(2236, 40) y:(2236, 2)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(f\"X:{X.shape} y:{y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa77694",
   "metadata": {},
   "source": [
    "El bloque realizara el k fold cross validation dividiendolo en 5 folds, se uso los MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4fcbace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_5.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_5.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341515e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
