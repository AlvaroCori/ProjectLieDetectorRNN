{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2afd9a5",
   "metadata": {},
   "source": [
    "## Antiguo proyecto de Redes Neuronales Recurrentes usando audios .wav, obteniendo su MFCC, aplicandolos a una RNN y validandolo con k fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37415a0a",
   "metadata": {},
   "source": [
    "#### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbcf75ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import soundfile as sf\n",
    "import json\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "import datetime\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.callbacks import EarlyStopping\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4830c4a",
   "metadata": {},
   "source": [
    "#### Funciones a usar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6ffb974",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Obtiene el path con el nombre de todos los archivos de un directorio.\n",
    "def get_files_from_path(directory):\n",
    "    path_files = []\n",
    "    dir_list = os.listdir(directory)\n",
    "    for path in dir_list:\n",
    "        path_files.append(directory+\"\\\\\"+path)\n",
    "    return path_files\n",
    "\n",
    "\n",
    "#Extrae los paths que cumplan con un codigo\n",
    "def extract_paths_for_emotions_keys(emotions_code, files_path, get_code):\n",
    "    paths = []\n",
    "    emotions_set = set(emotions_code)\n",
    "    for code_file in files_path:\n",
    "        if (get_code(code_file) in emotions_set):\n",
    "            paths.append(code_file)\n",
    "    return paths\n",
    "\n",
    "\n",
    "#Obtiene el codigo en el nombre del archivo para el dataset CREMA-D\n",
    "def get_code_esp(path):\n",
    "    return path[114]#path[110] prueba\n",
    "\n",
    "#Esta función abre el archivo .wav y obtiene el mfcc escalado en un vector de 40 elementos.\n",
    "def features_extractor(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio,sr=sample_rate,n_mfcc=40)\n",
    "    return mfccs_features\n",
    "\n",
    "\n",
    "#Esta función permite guardar los MFCC en 'features', el código en 'code' y su dirección en 'path' en un archivo json. \n",
    "def save_elements_in_json(examples_saved, name):\n",
    "    json_files = []\n",
    "    json_file = {}\n",
    "    index = 0\n",
    "    for file in examples_saved:\n",
    "        json_file = {\"id\": index, \"features\":[str(elem) for elem in file[0]] ,\"code\":file[1], \"path\":file[2]}\n",
    "        json_files.append(json_file)\n",
    "        index += 1\n",
    "    json_object = json.dumps(json_files)\n",
    "    with open(f\"{name}.json\", \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "   \n",
    "\n",
    "#La función permite cargar datos del MFCC y código desde un archivo json.\n",
    "def load_elements_from_json(name):\n",
    "    f = open(f'{name}.json')\n",
    "    data = json.load(f)\n",
    "    examples = []\n",
    "    for element in data:\n",
    "        examples.append(([float(feature) for feature in (element[\"features\"])], element[\"code\"]))\n",
    "    return examples\n",
    "\n",
    "\n",
    "#La función nos permite devolver una lista de MFCC obtenidos de una lista de paths. \n",
    "#El MFCC tiene un límite que no le permite cargar archivos menor o igual a 44 kb.\n",
    "#Con el diccionario obtenemos el total de audios recuperados por emoción.\n",
    "def get_features(paths,get_code, files_filters = dict()):\n",
    "    examples = []\n",
    "    for path in paths:\n",
    "        code = get_code(path)\n",
    "        file_stats = os.stat(path)\n",
    "        feature = features_extractor(path)\n",
    "        files_filters[code]+= 1\n",
    "        examples.append((feature,code))\n",
    "    print(f\"Se obtuvo el MFCC de unos {len(paths)} sobre {sum(files_filters[files] for files in files_filters)} audios.\")\n",
    "    return examples\n",
    "\n",
    "\n",
    "#Selecciona n ejemplos que necesitemos y los mezcla.\n",
    "def select_elements(examples, code, quantity, new_code):\n",
    "    random.shuffle(examples)\n",
    "    print(len(examples))\n",
    "    elements = []\n",
    "    counter = 1\n",
    "    for example in examples:\n",
    "        if (counter > quantity):\n",
    "            break\n",
    "        if code == example[1]:\n",
    "            elements.append((example[0],new_code))\n",
    "            counter = counter + 1\n",
    "    print(counter, len(elements))\n",
    "    return elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78e14ce",
   "metadata": {},
   "source": [
    "Los siguientes bloques obtienen los paths y filtra las emociones que necesitemos en cada dataset (CREMA-D y SAVEE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97450846",
   "metadata": {},
   "source": [
    "#### Funciones para obtener los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13f7c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtiene todos los datos de CREMA-D y SAVEE para un  \n",
    "def get_datas():\n",
    "    files_path = get_files_from_path(f\"{os.getcwd()}\\\\..\\\\..\\\\Datasets\\\\data\")\n",
    "    emotions_code = [\"t\", \"f\"]\n",
    "    datas_files = extract_paths_for_emotions_keys(emotions_code, files_path, get_code_esp)\n",
    "    examples = []\n",
    "    files_filters = dict()\n",
    "    files_filters[\"t\"] = 0\n",
    "    files_filters[\"f\"] = 0\n",
    "    examples = get_features(datas_files, get_code_esp, files_filters)\n",
    "    return examples\n",
    "\n",
    "#Obtiene los datos de entrada para la red neuronal x: mfcc normalizados, y: labeles categorizados\n",
    "def get_entries():\n",
    "    all_examples = get_datas()\n",
    "    entries = []\n",
    "    for example in all_examples:\n",
    "        entries.append((example[0], example[1]))\n",
    "    datas = select_elements(entries, 't', 400,\"without_stress\")\n",
    "    datas += select_elements(entries, 'f', 400, \"stress\")\n",
    "    random.shuffle(datas)\n",
    "    X = []\n",
    "    y = []\n",
    "    for data in datas:\n",
    "        X.append(data[0])\n",
    "        y.append(data[1])\n",
    "    labelencoder=preprocessing.LabelEncoder()\n",
    "    y = to_categorical(labelencoder.fit_transform(y))\n",
    "    return X, y\n",
    "\n",
    "#Obtiene los datos divididos de entrenamiento y tests\n",
    "def obtain_datas_train_and_test(percentage):\n",
    "    X, y = get_entries()\n",
    "    X_resized = []\n",
    "    for example in X:\n",
    "        x_sample = example.reshape((40, 431, 1))\n",
    "        X_resized.append(x_sample)\n",
    "    X_resized = np.array(X_resized)\n",
    "    X_test, X_train, y_test, y_train = train_test_split(X_resized, y, test_size =percentage,random_state=0)\n",
    "    '''\n",
    "    y = np.array(y)\n",
    "    print(len(X_train), len(X_train[0]))\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    '''\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff362da0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se obtuvo el MFCC de unos 800 sobre 800 audios.\n",
      "800\n",
      "401 400\n",
      "800\n",
      "401 400\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 16680 into shape (40,431,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m obtain_datas_train_and_test(\u001b[38;5;241m0.8\u001b[39m)\n\u001b[0;32m      2\u001b[0m num_labels \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m y_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn [4], line 36\u001b[0m, in \u001b[0;36mobtain_datas_train_and_test\u001b[1;34m(percentage)\u001b[0m\n\u001b[0;32m     34\u001b[0m X_resized \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m X:\n\u001b[1;32m---> 36\u001b[0m     x_sample \u001b[38;5;241m=\u001b[39m \u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m431\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     X_resized\u001b[38;5;241m.\u001b[39mappend(x_sample)\n\u001b[0;32m     38\u001b[0m X_resized \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_resized)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 16680 into shape (40,431,1)"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = obtain_datas_train_and_test(0.8)\n",
    "num_labels = y_train.shape[1] + y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "448e52ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdcf0115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(448, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f5b0d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc211300",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def new_RNN():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50,input_shape= dim_entrada, return_sequences=False))\n",
    "#    model.add(LSTM(units=16,input_shape= dim_entrada, return_sequences=True))\n",
    "#    model.add(LSTM(units=4,input_shape= dim_entrada, return_sequences=False))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
    "    return model\n",
    "    \n",
    "    def new_RNN():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, input_shape = dim_entrada))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
    "    return model\n",
    "    \n",
    "    tang_hiperbolica\n",
    "'''\n",
    "#redes neuronales recurrentes\n",
    "#Datos son audios convertidos a MFCC \n",
    "#mayor accuracy o (porcentaje de aciertos) \n",
    "\n",
    "\n",
    "#probando nueva arquitectura\n",
    "def new_RNN():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=16, kernel_size=2, activation='softmax', input_shape=(40, 431, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    #model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    #model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    model.add(Flatten())\n",
    "    #model.add(Dense(64, activation='softmax'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "111940c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_17 (Conv2D)          (None, 39, 430, 16)       80        \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 9, 107, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 15408)             0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 2)                 30818     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,898\n",
      "Trainable params: 30,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = new_RNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "941cf153",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'j' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m j\n\u001b[0;32m      2\u001b[0m k_fold \u001b[38;5;241m=\u001b[39m KFold(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      3\u001b[0m fold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'j' is not defined"
     ]
    }
   ],
   "source": [
    "k_fold = KFold(5)\n",
    "fold = 0\n",
    "y_tests = []\n",
    "predictions = []\n",
    "scores = []\n",
    "X = np.concatenate((X_train, X_test))\n",
    "y = np.concatenate((y_train, y_test))\n",
    "for train, test in k_fold.split(X):\n",
    "    fold = fold + 1\n",
    "    print(f\"Fold #{fold}\")\n",
    "    X_train = X[train]\n",
    "    X_test = X[test]\n",
    "    y_train = y[train]\n",
    "    y_test = y[test]\n",
    "    print(f\"Train - X:{X_train.shape} y:{y_train.shape}\")\n",
    "    print(f\"Test - X:{X_test.shape} y:{y_test.shape}\")\n",
    "    \n",
    "    num_labels = y.shape[1]\n",
    "    dim_entrada = (X_train.shape[1],1)\n",
    "\n",
    "    #model = new_RNN()\n",
    "    model = new_RNN()\n",
    "    callbacks = []\n",
    "    '''\n",
    "    callbacks = [\n",
    "    EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            min_delta=1e-2,\n",
    "            patience=20,\n",
    "            verbose=1,\n",
    "        )\n",
    "    ]\n",
    "    '''\n",
    "    num_epochs = 50\n",
    "    num_batch_size = 40\n",
    "    start = datetime.datetime.now()\n",
    "   \n",
    "    results = model.fit(X_train, y_train, batch_size=num_batch_size,epochs=num_epochs, validation_data=(X_test, y_test),callbacks=callbacks)\n",
    "\n",
    "    pred = model.predict(X_test)\n",
    "    y_tests.append(y_test)\n",
    "    pred=[([1,0] if i[0]>i[1] else [0,1]) for i in pred]\n",
    "    predictions.append(pred)\n",
    "    score = metrics.accuracy_score(pred, y_test)\n",
    "    math = confusion_matrix([(1 if x[0]==1 else 0) for x in pred],[(1 if x[0]==1 else 0) for x in y_test], labels=[1,0])\n",
    "    scores.append([score])\n",
    "    print(f\"Fold score (Accuracy score): {score}\")\n",
    "    print(\"Matriz de confusion\")\n",
    "    print(\"-------------------\")\n",
    "    print(\"---------| Verdadero | Falso |\")\n",
    "    print(f\"Verdadero|  {math[0][0]}        {math[0][1]}\")\n",
    "    print(f\"Falso    |  {math[1][0]}        {math[1][1]}\")\n",
    "\n",
    "y_tests = np.concatenate(y_tests)\n",
    "predictions = np.concatenate(predictions)\n",
    "score = metrics.accuracy_score(predictions, y_tests)\n",
    "print(\"-----------------------\")\n",
    "print(f\"Cross-validated score (Accuracy score): {score}\")\n",
    "print(\"-----------------------\")\n",
    "print(\"Resumen\")\n",
    "for result in scores:\n",
    "    print(f\"Fold score (Accuracy score): {result[0]}\")\n",
    "    \n",
    "#https://github.com/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_05_2_kfold.ipynb\n",
    "#https://www.youtube.com/watch?v=maiQf8ray_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7bc2e9ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_19 (Conv2D)          (None, 39, 430, 16)       80        \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 9, 107, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 15408)             0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 2)                 30818     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,898\n",
      "Trainable params: 30,898\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "14/14 [==============================] - 3s 140ms/step - loss: 1.2833 - accuracy: 0.5022 - val_loss: 0.7361 - val_accuracy: 0.4911\n",
      "Epoch 2/400\n",
      "14/14 [==============================] - 2s 121ms/step - loss: 0.7595 - accuracy: 0.5536 - val_loss: 0.9135 - val_accuracy: 0.5179\n",
      "Epoch 3/400\n",
      "14/14 [==============================] - 2s 121ms/step - loss: 0.7240 - accuracy: 0.5558 - val_loss: 0.8557 - val_accuracy: 0.4732\n",
      "Epoch 4/400\n",
      "14/14 [==============================] - 2s 123ms/step - loss: 0.5389 - accuracy: 0.7902 - val_loss: 0.7375 - val_accuracy: 0.4554\n",
      "Epoch 5/400\n",
      "14/14 [==============================] - 2s 119ms/step - loss: 0.4881 - accuracy: 0.7701 - val_loss: 0.8791 - val_accuracy: 0.5179\n",
      "Epoch 6/400\n",
      "14/14 [==============================] - 2s 120ms/step - loss: 0.5099 - accuracy: 0.7054 - val_loss: 0.9203 - val_accuracy: 0.5089\n",
      "Epoch 7/400\n",
      "14/14 [==============================] - 2s 118ms/step - loss: 0.4301 - accuracy: 0.8259 - val_loss: 0.7755 - val_accuracy: 0.4911\n",
      "Epoch 8/400\n",
      "14/14 [==============================] - 2s 135ms/step - loss: 0.3322 - accuracy: 0.9576 - val_loss: 0.8033 - val_accuracy: 0.5268\n",
      "Epoch 9/400\n",
      "14/14 [==============================] - 3s 222ms/step - loss: 0.3159 - accuracy: 0.9375 - val_loss: 0.7747 - val_accuracy: 0.5000\n",
      "Epoch 10/400\n",
      "14/14 [==============================] - 2s 176ms/step - loss: 0.2634 - accuracy: 0.9732 - val_loss: 0.7999 - val_accuracy: 0.5179\n",
      "Epoch 11/400\n",
      "14/14 [==============================] - 2s 177ms/step - loss: 0.2316 - accuracy: 0.9821 - val_loss: 0.7812 - val_accuracy: 0.5268\n",
      "Epoch 12/400\n",
      "14/14 [==============================] - 2s 180ms/step - loss: 0.2069 - accuracy: 0.9888 - val_loss: 0.8500 - val_accuracy: 0.5000\n",
      "Epoch 13/400\n",
      "14/14 [==============================] - 3s 182ms/step - loss: 0.1879 - accuracy: 0.9888 - val_loss: 0.8107 - val_accuracy: 0.5000\n",
      "Epoch 14/400\n",
      "14/14 [==============================] - 2s 175ms/step - loss: 0.1671 - accuracy: 0.9911 - val_loss: 0.8363 - val_accuracy: 0.5089\n",
      "Epoch 15/400\n",
      "14/14 [==============================] - 3s 195ms/step - loss: 0.1452 - accuracy: 0.9911 - val_loss: 0.8119 - val_accuracy: 0.5357\n",
      "Epoch 16/400\n",
      "14/14 [==============================] - 2s 167ms/step - loss: 0.1407 - accuracy: 0.9911 - val_loss: 0.8577 - val_accuracy: 0.4643\n",
      "Epoch 17/400\n",
      "14/14 [==============================] - 3s 182ms/step - loss: 0.1159 - accuracy: 0.9911 - val_loss: 0.8380 - val_accuracy: 0.5089\n",
      "Epoch 18/400\n",
      "14/14 [==============================] - 2s 157ms/step - loss: 0.1060 - accuracy: 0.9933 - val_loss: 0.8536 - val_accuracy: 0.5000\n",
      "Epoch 19/400\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.0979 - accuracy: 0.9933 - val_loss: 0.8403 - val_accuracy: 0.5268\n",
      "Epoch 20/400\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.0868 - accuracy: 0.9911 - val_loss: 0.8527 - val_accuracy: 0.5357\n",
      "Epoch 21/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0836 - accuracy: 0.9933 - val_loss: 0.9068 - val_accuracy: 0.5357\n",
      "Epoch 22/400\n",
      "14/14 [==============================] - 2s 157ms/step - loss: 0.0801 - accuracy: 0.9911 - val_loss: 0.8757 - val_accuracy: 0.5268\n",
      "Epoch 23/400\n",
      "14/14 [==============================] - 2s 163ms/step - loss: 0.0729 - accuracy: 0.9888 - val_loss: 0.9127 - val_accuracy: 0.5179\n",
      "Epoch 24/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0664 - accuracy: 0.9911 - val_loss: 0.8902 - val_accuracy: 0.5268\n",
      "Epoch 25/400\n",
      "14/14 [==============================] - 2s 138ms/step - loss: 0.0607 - accuracy: 0.9933 - val_loss: 0.8840 - val_accuracy: 0.5179\n",
      "Epoch 26/400\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0652 - accuracy: 0.9911 - val_loss: 0.9025 - val_accuracy: 0.5179\n",
      "Epoch 27/400\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.0684 - accuracy: 0.9955 - val_loss: 0.9014 - val_accuracy: 0.5089\n",
      "Epoch 28/400\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.0573 - accuracy: 0.9911 - val_loss: 0.9077 - val_accuracy: 0.5268\n",
      "Epoch 29/400\n",
      "14/14 [==============================] - 2s 163ms/step - loss: 0.0526 - accuracy: 0.9888 - val_loss: 0.9130 - val_accuracy: 0.5000\n",
      "Epoch 30/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0496 - accuracy: 0.9933 - val_loss: 0.9465 - val_accuracy: 0.5268\n",
      "Epoch 31/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0444 - accuracy: 0.9911 - val_loss: 0.9278 - val_accuracy: 0.5000\n",
      "Epoch 32/400\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.0431 - accuracy: 0.9888 - val_loss: 0.9353 - val_accuracy: 0.5179\n",
      "Epoch 33/400\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.0478 - accuracy: 0.9911 - val_loss: 0.9908 - val_accuracy: 0.5357\n",
      "Epoch 34/400\n",
      "14/14 [==============================] - 2s 163ms/step - loss: 0.0447 - accuracy: 0.9933 - val_loss: 0.9482 - val_accuracy: 0.5179\n",
      "Epoch 35/400\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0378 - accuracy: 0.9933 - val_loss: 0.9936 - val_accuracy: 0.5179\n",
      "Epoch 36/400\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.0398 - accuracy: 0.9911 - val_loss: 0.9599 - val_accuracy: 0.5089\n",
      "Epoch 37/400\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.0346 - accuracy: 0.9933 - val_loss: 0.9648 - val_accuracy: 0.5089\n",
      "Epoch 38/400\n",
      "14/14 [==============================] - 2s 168ms/step - loss: 0.0339 - accuracy: 0.9888 - val_loss: 1.0120 - val_accuracy: 0.5179\n",
      "Epoch 39/400\n",
      "14/14 [==============================] - 3s 183ms/step - loss: 0.0387 - accuracy: 0.9911 - val_loss: 0.9716 - val_accuracy: 0.5000\n",
      "Epoch 40/400\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0353 - accuracy: 0.9888 - val_loss: 1.0370 - val_accuracy: 0.4911\n",
      "Epoch 41/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0335 - accuracy: 0.9911 - val_loss: 0.9956 - val_accuracy: 0.5179\n",
      "Epoch 42/400\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.0323 - accuracy: 0.9933 - val_loss: 0.9996 - val_accuracy: 0.5089\n",
      "Epoch 43/400\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0300 - accuracy: 0.9911 - val_loss: 0.9998 - val_accuracy: 0.5179\n",
      "Epoch 44/400\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0296 - accuracy: 0.9911 - val_loss: 1.0026 - val_accuracy: 0.5089\n",
      "Epoch 45/400\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.0357 - accuracy: 0.9911 - val_loss: 1.0076 - val_accuracy: 0.5179\n",
      "Epoch 46/400\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.0299 - accuracy: 0.9911 - val_loss: 1.0105 - val_accuracy: 0.5179\n",
      "Epoch 47/400\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0298 - accuracy: 0.9911 - val_loss: 1.1009 - val_accuracy: 0.5179\n",
      "Epoch 48/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0300 - accuracy: 0.9933 - val_loss: 1.1506 - val_accuracy: 0.4911\n",
      "Epoch 49/400\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.0332 - accuracy: 0.9933 - val_loss: 1.1050 - val_accuracy: 0.5268\n",
      "Epoch 50/400\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0253 - accuracy: 0.9911 - val_loss: 1.1033 - val_accuracy: 0.5268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/400\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.0259 - accuracy: 0.9933 - val_loss: 1.0347 - val_accuracy: 0.4911\n",
      "Epoch 52/400\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.0265 - accuracy: 0.9888 - val_loss: 1.0502 - val_accuracy: 0.4911\n",
      "Epoch 53/400\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0262 - accuracy: 0.9888 - val_loss: 1.0415 - val_accuracy: 0.5268\n",
      "Epoch 54/400\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.0250 - accuracy: 0.9933 - val_loss: 1.0846 - val_accuracy: 0.5179\n",
      "Epoch 55/400\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.0279 - accuracy: 0.9911 - val_loss: 1.0886 - val_accuracy: 0.5179\n",
      "Epoch 56/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 1.1076 - val_accuracy: 0.4821\n",
      "Epoch 57/400\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0276 - accuracy: 0.9933 - val_loss: 1.1526 - val_accuracy: 0.5000\n",
      "Epoch 58/400\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 1.0693 - val_accuracy: 0.5089\n",
      "Epoch 59/400\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.0209 - accuracy: 0.9911 - val_loss: 1.0849 - val_accuracy: 0.5000\n",
      "Epoch 60/400\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 1.0963 - val_accuracy: 0.5000\n",
      "Epoch 61/400\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0296 - accuracy: 0.9933 - val_loss: 1.3080 - val_accuracy: 0.5268\n",
      "Epoch 62/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0368 - accuracy: 0.9933 - val_loss: 1.5287 - val_accuracy: 0.4911\n",
      "Epoch 63/400\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.0257 - accuracy: 0.9955 - val_loss: 1.1130 - val_accuracy: 0.5000\n",
      "Epoch 64/400\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 1.2096 - val_accuracy: 0.5089\n",
      "Epoch 65/400\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0232 - accuracy: 0.9933 - val_loss: 1.1022 - val_accuracy: 0.5089\n",
      "Epoch 66/400\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0321 - accuracy: 0.9888 - val_loss: 1.2849 - val_accuracy: 0.5000\n",
      "Epoch 67/400\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.0274 - accuracy: 0.9911 - val_loss: 1.1404 - val_accuracy: 0.5446\n",
      "Epoch 68/400\n",
      "14/14 [==============================] - 2s 156ms/step - loss: 0.0243 - accuracy: 0.9866 - val_loss: 1.1194 - val_accuracy: 0.5000\n",
      "Epoch 69/400\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0202 - accuracy: 0.9933 - val_loss: 1.1209 - val_accuracy: 0.5357\n",
      "Epoch 70/400\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.0287 - accuracy: 0.9933 - val_loss: 1.1232 - val_accuracy: 0.4911\n",
      "Epoch 71/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0244 - accuracy: 0.9911 - val_loss: 1.1254 - val_accuracy: 0.4911\n",
      "Epoch 72/400\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 1.1599 - val_accuracy: 0.5268\n",
      "Epoch 73/400\n",
      "14/14 [==============================] - 2s 156ms/step - loss: 0.0187 - accuracy: 0.9955 - val_loss: 1.3493 - val_accuracy: 0.5000\n",
      "Epoch 74/400\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0282 - accuracy: 0.9911 - val_loss: 1.1617 - val_accuracy: 0.4911\n",
      "Epoch 75/400\n",
      "14/14 [==============================] - 2s 157ms/step - loss: 0.0176 - accuracy: 0.9911 - val_loss: 1.1761 - val_accuracy: 0.5268\n",
      "Epoch 76/400\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.0201 - accuracy: 0.9911 - val_loss: 1.1879 - val_accuracy: 0.4911\n",
      "Epoch 77/400\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0217 - accuracy: 0.9866 - val_loss: 1.1625 - val_accuracy: 0.5000\n",
      "Epoch 78/400\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.0151 - accuracy: 0.9933 - val_loss: 1.1470 - val_accuracy: 0.5268\n",
      "Epoch 79/400\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0249 - accuracy: 0.9911 - val_loss: 1.1652 - val_accuracy: 0.4911\n",
      "Epoch 80/400\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.0192 - accuracy: 0.9911 - val_loss: 1.1637 - val_accuracy: 0.4732\n",
      "Epoch 81/400\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0193 - accuracy: 0.9911 - val_loss: 1.3104 - val_accuracy: 0.4911\n",
      "Epoch 82/400\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 1.1630 - val_accuracy: 0.5000\n",
      "Epoch 83/400\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0217 - accuracy: 0.9911 - val_loss: 1.2814 - val_accuracy: 0.5179\n",
      "Epoch 84/400\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.0237 - accuracy: 0.9933 - val_loss: 1.4370 - val_accuracy: 0.5089\n",
      "Epoch 85/400\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.0215 - accuracy: 0.9933 - val_loss: 1.1825 - val_accuracy: 0.5000\n",
      "Epoch 86/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0278 - accuracy: 0.9866 - val_loss: 1.1765 - val_accuracy: 0.4911\n",
      "Epoch 87/400\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0179 - accuracy: 0.9955 - val_loss: 1.6190 - val_accuracy: 0.5089\n",
      "Epoch 88/400\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0208 - accuracy: 0.9911 - val_loss: 1.1904 - val_accuracy: 0.5089\n",
      "Epoch 89/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 1.2748 - val_accuracy: 0.5000\n",
      "Epoch 90/400\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0270 - accuracy: 0.9978 - val_loss: 1.3174 - val_accuracy: 0.4911\n",
      "Epoch 91/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0337 - accuracy: 0.9911 - val_loss: 1.1977 - val_accuracy: 0.5000\n",
      "Epoch 92/400\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0231 - accuracy: 0.9911 - val_loss: 1.2358 - val_accuracy: 0.5000\n",
      "Epoch 93/400\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0233 - accuracy: 0.9911 - val_loss: 1.2122 - val_accuracy: 0.4821\n",
      "Epoch 94/400\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0230 - accuracy: 0.9911 - val_loss: 1.1991 - val_accuracy: 0.5179\n",
      "Epoch 95/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0264 - accuracy: 0.9888 - val_loss: 1.1988 - val_accuracy: 0.4911\n",
      "Epoch 96/400\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0345 - accuracy: 0.9933 - val_loss: 1.2981 - val_accuracy: 0.5179\n",
      "Epoch 97/400\n",
      "14/14 [==============================] - 2s 164ms/step - loss: 0.0285 - accuracy: 0.9888 - val_loss: 1.3209 - val_accuracy: 0.5000\n",
      "Epoch 98/400\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.0260 - accuracy: 0.9888 - val_loss: 1.2371 - val_accuracy: 0.5000\n",
      "Epoch 99/400\n",
      "14/14 [==============================] - 2s 164ms/step - loss: 0.0246 - accuracy: 0.9955 - val_loss: 1.5000 - val_accuracy: 0.5179\n",
      "Epoch 100/400\n",
      "14/14 [==============================] - 2s 174ms/step - loss: 0.0178 - accuracy: 0.9933 - val_loss: 1.2299 - val_accuracy: 0.4732\n",
      "Epoch 101/400\n",
      "14/14 [==============================] - 2s 179ms/step - loss: 0.0282 - accuracy: 0.9888 - val_loss: 1.4848 - val_accuracy: 0.5089\n",
      "Epoch 102/400\n",
      "14/14 [==============================] - 2s 171ms/step - loss: 0.0372 - accuracy: 0.9911 - val_loss: 1.2841 - val_accuracy: 0.5000\n",
      "Epoch 103/400\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0305 - accuracy: 0.9911 - val_loss: 1.3497 - val_accuracy: 0.5179\n",
      "Epoch 104/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0269 - accuracy: 0.9888 - val_loss: 1.2586 - val_accuracy: 0.5000\n",
      "Epoch 105/400\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0226 - accuracy: 0.9866 - val_loss: 1.2715 - val_accuracy: 0.4821\n",
      "Epoch 106/400\n",
      "14/14 [==============================] - 2s 163ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 1.4785 - val_accuracy: 0.5000\n",
      "Epoch 107/400\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.0187 - accuracy: 0.9911 - val_loss: 1.3442 - val_accuracy: 0.5268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0290 - accuracy: 0.9911 - val_loss: 1.4091 - val_accuracy: 0.5089\n",
      "Epoch 109/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0476 - accuracy: 0.9911 - val_loss: 1.8266 - val_accuracy: 0.5179\n",
      "Epoch 110/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0288 - accuracy: 0.9933 - val_loss: 1.2774 - val_accuracy: 0.5089\n",
      "Epoch 111/400\n",
      "14/14 [==============================] - 2s 165ms/step - loss: 0.0263 - accuracy: 0.9911 - val_loss: 1.5836 - val_accuracy: 0.5089\n",
      "Epoch 112/400\n",
      "14/14 [==============================] - 2s 176ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 1.4839 - val_accuracy: 0.5089\n",
      "Epoch 113/400\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0299 - accuracy: 0.9911 - val_loss: 1.3446 - val_accuracy: 0.5089\n",
      "Epoch 114/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0239 - accuracy: 0.9911 - val_loss: 1.3924 - val_accuracy: 0.5000\n",
      "Epoch 115/400\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.0248 - accuracy: 0.9888 - val_loss: 1.3806 - val_accuracy: 0.4821\n",
      "Epoch 116/400\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.0225 - accuracy: 0.9933 - val_loss: 1.6043 - val_accuracy: 0.4821\n",
      "Epoch 117/400\n",
      "14/14 [==============================] - 2s 144ms/step - loss: 0.0495 - accuracy: 0.9911 - val_loss: 1.9464 - val_accuracy: 0.4821\n",
      "Epoch 118/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0317 - accuracy: 0.9955 - val_loss: 1.3636 - val_accuracy: 0.5179\n",
      "Epoch 119/400\n",
      "14/14 [==============================] - 2s 142ms/step - loss: 0.0353 - accuracy: 0.9933 - val_loss: 1.9387 - val_accuracy: 0.5179\n",
      "Epoch 120/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0140 - accuracy: 0.9955 - val_loss: 1.7544 - val_accuracy: 0.5000\n",
      "Epoch 121/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0360 - accuracy: 0.9933 - val_loss: 1.4620 - val_accuracy: 0.5089\n",
      "Epoch 122/400\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 1.4898 - val_accuracy: 0.5179\n",
      "Epoch 123/400\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0246 - accuracy: 0.9911 - val_loss: 1.5370 - val_accuracy: 0.4911\n",
      "Epoch 124/400\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.0235 - accuracy: 0.9933 - val_loss: 1.3984 - val_accuracy: 0.5000\n",
      "Epoch 125/400\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 1.7536 - val_accuracy: 0.5179\n",
      "Epoch 126/400\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.0234 - accuracy: 0.9911 - val_loss: 1.4041 - val_accuracy: 0.4911\n",
      "Epoch 127/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0246 - accuracy: 0.9888 - val_loss: 1.4900 - val_accuracy: 0.4911\n",
      "Epoch 128/400\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.0235 - accuracy: 0.9911 - val_loss: 1.9376 - val_accuracy: 0.4911\n",
      "Epoch 129/400\n",
      "14/14 [==============================] - 2s 139ms/step - loss: 0.0369 - accuracy: 0.9911 - val_loss: 1.5786 - val_accuracy: 0.4911\n",
      "Epoch 130/400\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.0278 - accuracy: 0.9888 - val_loss: 1.5958 - val_accuracy: 0.5089\n",
      "Epoch 131/400\n",
      "14/14 [==============================] - 2s 139ms/step - loss: 0.0209 - accuracy: 0.9955 - val_loss: 1.4262 - val_accuracy: 0.5000\n",
      "Epoch 132/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0213 - accuracy: 0.9911 - val_loss: 1.4944 - val_accuracy: 0.5179\n",
      "Epoch 133/400\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.0223 - accuracy: 0.9911 - val_loss: 1.4116 - val_accuracy: 0.4911\n",
      "Epoch 134/400\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.0194 - accuracy: 0.9955 - val_loss: 1.7689 - val_accuracy: 0.5357\n",
      "Epoch 135/400\n",
      "14/14 [==============================] - 2s 144ms/step - loss: 0.0327 - accuracy: 0.9911 - val_loss: 1.6213 - val_accuracy: 0.5089\n",
      "Epoch 136/400\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.0170 - accuracy: 0.9955 - val_loss: 1.7907 - val_accuracy: 0.5179\n",
      "Epoch 137/400\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.0356 - accuracy: 0.9911 - val_loss: 1.3984 - val_accuracy: 0.5000\n",
      "Epoch 138/400\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0217 - accuracy: 0.9911 - val_loss: 1.3886 - val_accuracy: 0.5089\n",
      "Epoch 139/400\n",
      "14/14 [==============================] - 2s 142ms/step - loss: 0.0366 - accuracy: 0.9888 - val_loss: 1.3433 - val_accuracy: 0.5000\n",
      "Epoch 140/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0212 - accuracy: 0.9911 - val_loss: 1.3606 - val_accuracy: 0.4911\n",
      "Epoch 141/400\n",
      "14/14 [==============================] - 2s 140ms/step - loss: 0.0184 - accuracy: 0.9866 - val_loss: 1.3444 - val_accuracy: 0.5000\n",
      "Epoch 142/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 1.4338 - val_accuracy: 0.5179\n",
      "Epoch 143/400\n",
      "14/14 [==============================] - 2s 135ms/step - loss: 0.0197 - accuracy: 0.9955 - val_loss: 1.8803 - val_accuracy: 0.5089\n",
      "Epoch 144/400\n",
      "14/14 [==============================] - 2s 123ms/step - loss: 0.0269 - accuracy: 0.9911 - val_loss: 1.6873 - val_accuracy: 0.5179\n",
      "Epoch 145/400\n",
      "14/14 [==============================] - 2s 157ms/step - loss: 0.0219 - accuracy: 0.9933 - val_loss: 1.8425 - val_accuracy: 0.5357\n",
      "Epoch 146/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0461 - accuracy: 0.9888 - val_loss: 1.6487 - val_accuracy: 0.4911\n",
      "Epoch 147/400\n",
      "14/14 [==============================] - 2s 160ms/step - loss: 0.0444 - accuracy: 0.9888 - val_loss: 1.7865 - val_accuracy: 0.5268\n",
      "Epoch 148/400\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 1.3829 - val_accuracy: 0.4732\n",
      "Epoch 149/400\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.0182 - accuracy: 0.9911 - val_loss: 1.4025 - val_accuracy: 0.5000\n",
      "Epoch 150/400\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0437 - accuracy: 0.9888 - val_loss: 1.3725 - val_accuracy: 0.4643\n",
      "Epoch 151/400\n",
      "14/14 [==============================] - 2s 167ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 1.8981 - val_accuracy: 0.5179\n",
      "Epoch 152/400\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.0237 - accuracy: 0.9911 - val_loss: 1.4364 - val_accuracy: 0.5000\n",
      "Epoch 153/400\n",
      "14/14 [==============================] - 2s 157ms/step - loss: 0.0229 - accuracy: 0.9911 - val_loss: 1.4290 - val_accuracy: 0.5000\n",
      "Epoch 154/400\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 1.9745 - val_accuracy: 0.5000\n",
      "Epoch 155/400\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0783 - accuracy: 0.9866 - val_loss: 2.6535 - val_accuracy: 0.4732\n",
      "Epoch 156/400\n",
      "14/14 [==============================] - 2s 172ms/step - loss: 0.0514 - accuracy: 0.9911 - val_loss: 2.2065 - val_accuracy: 0.4911\n",
      "Epoch 157/400\n",
      "14/14 [==============================] - 2s 174ms/step - loss: 0.0518 - accuracy: 0.9911 - val_loss: 1.9335 - val_accuracy: 0.5089\n",
      "Epoch 158/400\n",
      "14/14 [==============================] - 2s 157ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 1.5396 - val_accuracy: 0.5268\n",
      "Epoch 159/400\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0381 - accuracy: 0.9888 - val_loss: 1.4759 - val_accuracy: 0.4911\n",
      "Epoch 160/400\n",
      "14/14 [==============================] - 2s 142ms/step - loss: 0.0290 - accuracy: 0.9911 - val_loss: 1.6785 - val_accuracy: 0.4911\n",
      "Epoch 161/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0303 - accuracy: 0.9933 - val_loss: 2.1427 - val_accuracy: 0.4911\n",
      "Epoch 162/400\n",
      "14/14 [==============================] - 2s 139ms/step - loss: 0.0323 - accuracy: 0.9911 - val_loss: 1.7839 - val_accuracy: 0.5179\n",
      "Epoch 163/400\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0399 - accuracy: 0.9866 - val_loss: 1.4507 - val_accuracy: 0.4732\n",
      "Epoch 164/400\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 1.6669 - val_accuracy: 0.5179\n",
      "Epoch 165/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0184 - accuracy: 0.9955 - val_loss: 1.4324 - val_accuracy: 0.4821\n",
      "Epoch 166/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0320 - accuracy: 0.9911 - val_loss: 1.5689 - val_accuracy: 0.5000\n",
      "Epoch 167/400\n",
      "14/14 [==============================] - 2s 138ms/step - loss: 0.0254 - accuracy: 0.9933 - val_loss: 1.9548 - val_accuracy: 0.5268\n",
      "Epoch 168/400\n",
      "14/14 [==============================] - 2s 139ms/step - loss: 0.0254 - accuracy: 0.9911 - val_loss: 1.4971 - val_accuracy: 0.5000\n",
      "Epoch 169/400\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 0.0163 - accuracy: 0.9911 - val_loss: 1.4293 - val_accuracy: 0.4732\n",
      "Epoch 170/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0285 - accuracy: 0.9933 - val_loss: 2.9378 - val_accuracy: 0.5268\n",
      "Epoch 171/400\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0788 - accuracy: 0.9911 - val_loss: 2.8133 - val_accuracy: 0.4732\n",
      "Epoch 172/400\n",
      "14/14 [==============================] - 2s 140ms/step - loss: 0.0548 - accuracy: 0.9933 - val_loss: 1.8737 - val_accuracy: 0.5179\n",
      "Epoch 173/400\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0354 - accuracy: 0.9866 - val_loss: 1.6678 - val_accuracy: 0.5179\n",
      "Epoch 174/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0165 - accuracy: 0.9911 - val_loss: 1.6983 - val_accuracy: 0.5179\n",
      "Epoch 175/400\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.0392 - accuracy: 0.9933 - val_loss: 2.0169 - val_accuracy: 0.5000\n",
      "Epoch 176/400\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0382 - accuracy: 0.9911 - val_loss: 2.6456 - val_accuracy: 0.4732\n",
      "Epoch 177/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0378 - accuracy: 0.9933 - val_loss: 1.7197 - val_accuracy: 0.5357\n",
      "Epoch 178/400\n",
      "14/14 [==============================] - 2s 167ms/step - loss: 0.0461 - accuracy: 0.9911 - val_loss: 2.9748 - val_accuracy: 0.5179\n",
      "Epoch 179/400\n",
      "14/14 [==============================] - 2s 171ms/step - loss: 0.0407 - accuracy: 0.9933 - val_loss: 1.5032 - val_accuracy: 0.4732\n",
      "Epoch 180/400\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0159 - accuracy: 0.9955 - val_loss: 2.7394 - val_accuracy: 0.4732\n",
      "Epoch 181/400\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.0663 - accuracy: 0.9866 - val_loss: 1.9866 - val_accuracy: 0.5000\n",
      "Epoch 182/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0167 - accuracy: 0.9933 - val_loss: 1.5390 - val_accuracy: 0.4911\n",
      "Epoch 183/400\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.0266 - accuracy: 0.9888 - val_loss: 2.2858 - val_accuracy: 0.5357\n",
      "Epoch 184/400\n",
      "14/14 [==============================] - 2s 168ms/step - loss: 0.0442 - accuracy: 0.9933 - val_loss: 1.7816 - val_accuracy: 0.4911\n",
      "Epoch 185/400\n",
      "14/14 [==============================] - 2s 173ms/step - loss: 0.0262 - accuracy: 0.9955 - val_loss: 3.1941 - val_accuracy: 0.4821\n",
      "Epoch 186/400\n",
      "14/14 [==============================] - 2s 142ms/step - loss: 0.0204 - accuracy: 0.9978 - val_loss: 1.5291 - val_accuracy: 0.4643\n",
      "Epoch 187/400\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.0499 - accuracy: 0.9933 - val_loss: 2.6286 - val_accuracy: 0.5000\n",
      "Epoch 188/400\n",
      "14/14 [==============================] - 2s 178ms/step - loss: 0.0299 - accuracy: 0.9911 - val_loss: 1.7646 - val_accuracy: 0.5000\n",
      "Epoch 189/400\n",
      "14/14 [==============================] - 3s 184ms/step - loss: 0.0212 - accuracy: 0.9911 - val_loss: 1.6417 - val_accuracy: 0.5179\n",
      "Epoch 190/400\n",
      "14/14 [==============================] - 2s 177ms/step - loss: 0.0325 - accuracy: 0.9888 - val_loss: 1.7077 - val_accuracy: 0.5000\n",
      "Epoch 191/400\n",
      "14/14 [==============================] - 3s 183ms/step - loss: 0.0270 - accuracy: 0.9888 - val_loss: 1.5551 - val_accuracy: 0.4643\n",
      "Epoch 192/400\n",
      "14/14 [==============================] - 2s 173ms/step - loss: 0.0334 - accuracy: 0.9888 - val_loss: 1.6032 - val_accuracy: 0.4911\n",
      "Epoch 193/400\n",
      "14/14 [==============================] - 2s 182ms/step - loss: 0.0262 - accuracy: 0.9933 - val_loss: 1.9103 - val_accuracy: 0.5268\n",
      "Epoch 194/400\n",
      "14/14 [==============================] - 3s 181ms/step - loss: 0.0393 - accuracy: 0.9911 - val_loss: 1.6045 - val_accuracy: 0.5000\n",
      "Epoch 195/400\n",
      "14/14 [==============================] - 2s 177ms/step - loss: 0.0319 - accuracy: 0.9911 - val_loss: 2.4418 - val_accuracy: 0.4911\n",
      "Epoch 196/400\n",
      "14/14 [==============================] - 2s 163ms/step - loss: 0.0166 - accuracy: 0.9955 - val_loss: 2.7529 - val_accuracy: 0.5357\n",
      "Epoch 197/400\n",
      "14/14 [==============================] - 3s 182ms/step - loss: 0.0557 - accuracy: 0.9933 - val_loss: 1.5690 - val_accuracy: 0.5000\n",
      "Epoch 198/400\n",
      "14/14 [==============================] - 2s 166ms/step - loss: 0.0293 - accuracy: 0.9911 - val_loss: 1.5660 - val_accuracy: 0.4554\n",
      "Epoch 199/400\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0337 - accuracy: 0.9933 - val_loss: 1.8316 - val_accuracy: 0.5357\n",
      "Epoch 200/400\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0208 - accuracy: 0.9955 - val_loss: 1.6555 - val_accuracy: 0.5179\n",
      "Epoch 201/400\n",
      "14/14 [==============================] - 2s 177ms/step - loss: 0.0341 - accuracy: 0.9888 - val_loss: 1.6513 - val_accuracy: 0.5179\n",
      "Epoch 202/400\n",
      "14/14 [==============================] - 3s 182ms/step - loss: 0.0152 - accuracy: 0.9933 - val_loss: 1.5953 - val_accuracy: 0.4821\n",
      "Epoch 203/400\n",
      "14/14 [==============================] - 3s 181ms/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 2.7806 - val_accuracy: 0.4732\n",
      "Epoch 204/400\n",
      "14/14 [==============================] - 2s 176ms/step - loss: 0.0346 - accuracy: 0.9933 - val_loss: 1.6909 - val_accuracy: 0.5179\n",
      "Epoch 205/400\n",
      "14/14 [==============================] - 2s 165ms/step - loss: 0.0324 - accuracy: 0.9933 - val_loss: 3.0227 - val_accuracy: 0.5357\n",
      "Epoch 206/400\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0167 - accuracy: 0.9955 - val_loss: 2.5484 - val_accuracy: 0.4821\n",
      "Epoch 207/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0291 - accuracy: 0.9911 - val_loss: 1.9540 - val_accuracy: 0.5268\n",
      "Epoch 208/400\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.0369 - accuracy: 0.9888 - val_loss: 2.9116 - val_accuracy: 0.5179\n",
      "Epoch 209/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0170 - accuracy: 0.9955 - val_loss: 2.6711 - val_accuracy: 0.4821\n",
      "Epoch 210/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0215 - accuracy: 0.9911 - val_loss: 1.6408 - val_accuracy: 0.4911\n",
      "Epoch 211/400\n",
      "14/14 [==============================] - 2s 138ms/step - loss: 0.0249 - accuracy: 0.9888 - val_loss: 1.7996 - val_accuracy: 0.4732\n",
      "Epoch 212/400\n",
      "14/14 [==============================] - 2s 138ms/step - loss: 0.0235 - accuracy: 0.9911 - val_loss: 2.0890 - val_accuracy: 0.5268\n",
      "Epoch 213/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0554 - accuracy: 0.9866 - val_loss: 1.9357 - val_accuracy: 0.5357\n",
      "Epoch 214/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0250 - accuracy: 0.9955 - val_loss: 1.5793 - val_accuracy: 0.4821\n",
      "Epoch 215/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0247 - accuracy: 0.9911 - val_loss: 1.6488 - val_accuracy: 0.4821\n",
      "Epoch 216/400\n",
      "14/14 [==============================] - 2s 140ms/step - loss: 0.0270 - accuracy: 0.9911 - val_loss: 1.6362 - val_accuracy: 0.5089\n",
      "Epoch 217/400\n",
      "14/14 [==============================] - 2s 139ms/step - loss: 0.0211 - accuracy: 0.9888 - val_loss: 1.7110 - val_accuracy: 0.4911\n",
      "Epoch 218/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0249 - accuracy: 0.9911 - val_loss: 1.5738 - val_accuracy: 0.4643\n",
      "Epoch 219/400\n",
      "14/14 [==============================] - 2s 135ms/step - loss: 0.0307 - accuracy: 0.9911 - val_loss: 2.2234 - val_accuracy: 0.5179\n",
      "Epoch 220/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 149ms/step - loss: 0.0225 - accuracy: 0.9955 - val_loss: 2.0241 - val_accuracy: 0.4821\n",
      "Epoch 221/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 1.6068 - val_accuracy: 0.5000\n",
      "Epoch 222/400\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.0183 - accuracy: 0.9933 - val_loss: 1.5824 - val_accuracy: 0.4732\n",
      "Epoch 223/400\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 1.5935 - val_accuracy: 0.4911\n",
      "Epoch 224/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0185 - accuracy: 0.9933 - val_loss: 1.5948 - val_accuracy: 0.5089\n",
      "Epoch 225/400\n",
      "14/14 [==============================] - 2s 131ms/step - loss: 0.0262 - accuracy: 0.9933 - val_loss: 2.1916 - val_accuracy: 0.5000\n",
      "Epoch 226/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0438 - accuracy: 0.9888 - val_loss: 1.6748 - val_accuracy: 0.4911\n",
      "Epoch 227/400\n",
      "14/14 [==============================] - 2s 142ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 3.2819 - val_accuracy: 0.5089\n",
      "Epoch 228/400\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 0.0656 - accuracy: 0.9866 - val_loss: 2.7735 - val_accuracy: 0.5357\n",
      "Epoch 229/400\n",
      "14/14 [==============================] - 2s 134ms/step - loss: 0.0560 - accuracy: 0.9933 - val_loss: 2.2825 - val_accuracy: 0.4911\n",
      "Epoch 230/400\n",
      "14/14 [==============================] - 2s 140ms/step - loss: 0.0366 - accuracy: 0.9933 - val_loss: 1.7182 - val_accuracy: 0.4821\n",
      "Epoch 231/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0222 - accuracy: 0.9955 - val_loss: 2.2454 - val_accuracy: 0.5268\n",
      "Epoch 232/400\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.0550 - accuracy: 0.9888 - val_loss: 1.6517 - val_accuracy: 0.5000\n",
      "Epoch 233/400\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 1.7444 - val_accuracy: 0.4911\n",
      "Epoch 234/400\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.0254 - accuracy: 0.9933 - val_loss: 2.3192 - val_accuracy: 0.5179\n",
      "Epoch 235/400\n",
      "14/14 [==============================] - 2s 160ms/step - loss: 0.0273 - accuracy: 0.9933 - val_loss: 2.2061 - val_accuracy: 0.5000\n",
      "Epoch 236/400\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.0419 - accuracy: 0.9911 - val_loss: 1.7179 - val_accuracy: 0.5357\n",
      "Epoch 237/400\n",
      "14/14 [==============================] - 2s 144ms/step - loss: 0.0339 - accuracy: 0.9888 - val_loss: 3.0559 - val_accuracy: 0.5179\n",
      "Epoch 238/400\n",
      "14/14 [==============================] - 2s 142ms/step - loss: 0.0254 - accuracy: 0.9978 - val_loss: 1.9028 - val_accuracy: 0.4911\n",
      "Epoch 239/400\n",
      "14/14 [==============================] - 2s 142ms/step - loss: 0.0248 - accuracy: 0.9933 - val_loss: 1.6328 - val_accuracy: 0.4821\n",
      "Epoch 240/400\n",
      "14/14 [==============================] - 2s 139ms/step - loss: 0.0304 - accuracy: 0.9911 - val_loss: 2.4597 - val_accuracy: 0.5268\n",
      "Epoch 241/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0536 - accuracy: 0.9888 - val_loss: 2.2246 - val_accuracy: 0.5179\n",
      "Epoch 242/400\n",
      "14/14 [==============================] - 3s 184ms/step - loss: 0.0392 - accuracy: 0.9933 - val_loss: 1.6323 - val_accuracy: 0.5089\n",
      "Epoch 243/400\n",
      "14/14 [==============================] - 3s 187ms/step - loss: 0.0299 - accuracy: 0.9911 - val_loss: 1.8126 - val_accuracy: 0.5268\n",
      "Epoch 244/400\n",
      "14/14 [==============================] - 3s 187ms/step - loss: 0.0171 - accuracy: 0.9933 - val_loss: 3.2688 - val_accuracy: 0.4732\n",
      "Epoch 245/400\n",
      "14/14 [==============================] - 3s 182ms/step - loss: 0.0732 - accuracy: 0.9888 - val_loss: 1.7044 - val_accuracy: 0.5000\n",
      "Epoch 246/400\n",
      "14/14 [==============================] - 2s 172ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 3.2848 - val_accuracy: 0.5357\n",
      "Epoch 247/400\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.0605 - accuracy: 0.9888 - val_loss: 2.0129 - val_accuracy: 0.5446\n",
      "Epoch 248/400\n",
      "14/14 [==============================] - 3s 188ms/step - loss: 0.0525 - accuracy: 0.9888 - val_loss: 1.7628 - val_accuracy: 0.4911\n",
      "Epoch 249/400\n",
      "14/14 [==============================] - 2s 166ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 1.7116 - val_accuracy: 0.5179\n",
      "Epoch 250/400\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0500 - accuracy: 0.9888 - val_loss: 1.7530 - val_accuracy: 0.5179\n",
      "Epoch 251/400\n",
      "14/14 [==============================] - 3s 194ms/step - loss: 0.0228 - accuracy: 0.9911 - val_loss: 2.1354 - val_accuracy: 0.4911\n",
      "Epoch 252/400\n",
      "14/14 [==============================] - 2s 168ms/step - loss: 0.0240 - accuracy: 0.9933 - val_loss: 2.5722 - val_accuracy: 0.5179\n",
      "Epoch 253/400\n",
      "14/14 [==============================] - 3s 205ms/step - loss: 0.0483 - accuracy: 0.9911 - val_loss: 1.9104 - val_accuracy: 0.4911\n",
      "Epoch 254/400\n",
      "14/14 [==============================] - 2s 167ms/step - loss: 0.0414 - accuracy: 0.9911 - val_loss: 2.0153 - val_accuracy: 0.4911\n",
      "Epoch 255/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0463 - accuracy: 0.9911 - val_loss: 1.6704 - val_accuracy: 0.5000\n",
      "Epoch 256/400\n",
      "14/14 [==============================] - 3s 190ms/step - loss: 0.0134 - accuracy: 0.9911 - val_loss: 1.9538 - val_accuracy: 0.5357\n",
      "Epoch 257/400\n",
      "14/14 [==============================] - 3s 181ms/step - loss: 0.0441 - accuracy: 0.9911 - val_loss: 1.8516 - val_accuracy: 0.5446\n",
      "Epoch 258/400\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.0435 - accuracy: 0.9911 - val_loss: 1.6630 - val_accuracy: 0.5000\n",
      "Epoch 259/400\n",
      "14/14 [==============================] - 2s 166ms/step - loss: 0.0289 - accuracy: 0.9933 - val_loss: 3.3745 - val_accuracy: 0.4732\n",
      "Epoch 260/400\n",
      "14/14 [==============================] - 2s 168ms/step - loss: 0.0419 - accuracy: 0.9955 - val_loss: 2.1762 - val_accuracy: 0.4821\n",
      "Epoch 261/400\n",
      "14/14 [==============================] - 2s 175ms/step - loss: 0.0467 - accuracy: 0.9933 - val_loss: 2.3904 - val_accuracy: 0.5268\n",
      "Epoch 262/400\n",
      "14/14 [==============================] - 3s 181ms/step - loss: 0.0249 - accuracy: 0.9955 - val_loss: 1.9927 - val_accuracy: 0.5000\n",
      "Epoch 263/400\n",
      "14/14 [==============================] - 3s 183ms/step - loss: 0.0269 - accuracy: 0.9933 - val_loss: 1.7859 - val_accuracy: 0.5089\n",
      "Epoch 264/400\n",
      "14/14 [==============================] - 2s 160ms/step - loss: 0.0304 - accuracy: 0.9911 - val_loss: 1.7929 - val_accuracy: 0.5000\n",
      "Epoch 265/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0249 - accuracy: 0.9888 - val_loss: 1.6982 - val_accuracy: 0.4554\n",
      "Epoch 266/400\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.0226 - accuracy: 0.9911 - val_loss: 1.6923 - val_accuracy: 0.4643\n",
      "Epoch 267/400\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0258 - accuracy: 0.9888 - val_loss: 1.6938 - val_accuracy: 0.4732\n",
      "Epoch 268/400\n",
      "14/14 [==============================] - 2s 163ms/step - loss: 0.0432 - accuracy: 0.9933 - val_loss: 3.2893 - val_accuracy: 0.5089\n",
      "Epoch 269/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0371 - accuracy: 0.9888 - val_loss: 1.7211 - val_accuracy: 0.4911\n",
      "Epoch 270/400\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.0233 - accuracy: 0.9933 - val_loss: 3.2497 - val_accuracy: 0.4732\n",
      "Epoch 271/400\n",
      "14/14 [==============================] - 2s 177ms/step - loss: 0.0563 - accuracy: 0.9888 - val_loss: 4.0947 - val_accuracy: 0.4911\n",
      "Epoch 272/400\n",
      "14/14 [==============================] - 2s 164ms/step - loss: 0.0246 - accuracy: 0.9933 - val_loss: 2.0698 - val_accuracy: 0.5357\n",
      "Epoch 273/400\n",
      "14/14 [==============================] - 3s 189ms/step - loss: 0.0540 - accuracy: 0.9911 - val_loss: 1.6569 - val_accuracy: 0.4821\n",
      "Epoch 274/400\n",
      "14/14 [==============================] - 3s 184ms/step - loss: 0.0250 - accuracy: 0.9955 - val_loss: 1.9168 - val_accuracy: 0.5179\n",
      "Epoch 275/400\n",
      "14/14 [==============================] - 3s 188ms/step - loss: 0.0631 - accuracy: 0.9933 - val_loss: 1.7261 - val_accuracy: 0.5089\n",
      "Epoch 276/400\n",
      "14/14 [==============================] - 3s 196ms/step - loss: 0.0266 - accuracy: 0.9888 - val_loss: 2.2201 - val_accuracy: 0.5000\n",
      "Epoch 277/400\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.0379 - accuracy: 0.9888 - val_loss: 1.7162 - val_accuracy: 0.4911\n",
      "Epoch 278/400\n",
      "14/14 [==============================] - 2s 167ms/step - loss: 0.0391 - accuracy: 0.9911 - val_loss: 3.1527 - val_accuracy: 0.5357\n",
      "Epoch 279/400\n",
      "14/14 [==============================] - 2s 169ms/step - loss: 0.0593 - accuracy: 0.9933 - val_loss: 1.9428 - val_accuracy: 0.5089\n",
      "Epoch 280/400\n",
      "14/14 [==============================] - 2s 156ms/step - loss: 0.0333 - accuracy: 0.9911 - val_loss: 1.7765 - val_accuracy: 0.4911\n",
      "Epoch 281/400\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0226 - accuracy: 0.9933 - val_loss: 2.6187 - val_accuracy: 0.5268\n",
      "Epoch 282/400\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0263 - accuracy: 0.9888 - val_loss: 1.8268 - val_accuracy: 0.5179\n",
      "Epoch 283/400\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.0211 - accuracy: 0.9911 - val_loss: 1.7348 - val_accuracy: 0.4911\n",
      "Epoch 284/400\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.0250 - accuracy: 0.9933 - val_loss: 2.0607 - val_accuracy: 0.5000\n",
      "Epoch 285/400\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0478 - accuracy: 0.9933 - val_loss: 2.1490 - val_accuracy: 0.5268\n",
      "Epoch 286/400\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 1.8892 - val_accuracy: 0.5179\n",
      "Epoch 287/400\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0340 - accuracy: 0.9933 - val_loss: 3.9718 - val_accuracy: 0.5357\n",
      "Epoch 288/400\n",
      "14/14 [==============================] - 2s 167ms/step - loss: 0.0397 - accuracy: 0.9911 - val_loss: 2.5828 - val_accuracy: 0.4911\n",
      "Epoch 289/400\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 1.7686 - val_accuracy: 0.5000\n",
      "Epoch 290/400\n",
      "14/14 [==============================] - 2s 171ms/step - loss: 0.0433 - accuracy: 0.9911 - val_loss: 1.7203 - val_accuracy: 0.4732\n",
      "Epoch 291/400\n",
      "14/14 [==============================] - 2s 172ms/step - loss: 0.0539 - accuracy: 0.9955 - val_loss: 1.8645 - val_accuracy: 0.5000\n",
      "Epoch 292/400\n",
      "14/14 [==============================] - 2s 172ms/step - loss: 0.0541 - accuracy: 0.9888 - val_loss: 3.8784 - val_accuracy: 0.4911\n",
      "Epoch 293/400\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0373 - accuracy: 0.9933 - val_loss: 1.9817 - val_accuracy: 0.5268\n",
      "Epoch 294/400\n",
      "14/14 [==============================] - 2s 166ms/step - loss: 0.0405 - accuracy: 0.9911 - val_loss: 2.8919 - val_accuracy: 0.5268\n",
      "Epoch 295/400\n",
      "14/14 [==============================] - 2s 160ms/step - loss: 0.0347 - accuracy: 0.9911 - val_loss: 1.9387 - val_accuracy: 0.5179\n",
      "Epoch 296/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0313 - accuracy: 0.9888 - val_loss: 2.3071 - val_accuracy: 0.5268\n",
      "Epoch 297/400\n",
      "14/14 [==============================] - 2s 156ms/step - loss: 0.0112 - accuracy: 0.9955 - val_loss: 3.1466 - val_accuracy: 0.4821\n",
      "Epoch 298/400\n",
      "14/14 [==============================] - 2s 157ms/step - loss: 0.0641 - accuracy: 0.9933 - val_loss: 2.2093 - val_accuracy: 0.5446\n",
      "Epoch 299/400\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0116 - accuracy: 0.9978 - val_loss: 2.2478 - val_accuracy: 0.5000\n",
      "Epoch 300/400\n",
      "14/14 [==============================] - 2s 176ms/step - loss: 0.0356 - accuracy: 0.9933 - val_loss: 1.9860 - val_accuracy: 0.5357\n",
      "Epoch 301/400\n",
      "14/14 [==============================] - 2s 162ms/step - loss: 0.0375 - accuracy: 0.9911 - val_loss: 2.1532 - val_accuracy: 0.5179\n",
      "Epoch 302/400\n",
      "14/14 [==============================] - 2s 172ms/step - loss: 0.0303 - accuracy: 0.9933 - val_loss: 3.3941 - val_accuracy: 0.4732\n",
      "Epoch 303/400\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0219 - accuracy: 0.9911 - val_loss: 1.9798 - val_accuracy: 0.5000\n",
      "Epoch 304/400\n",
      "14/14 [==============================] - 3s 187ms/step - loss: 0.0248 - accuracy: 0.9911 - val_loss: 1.8921 - val_accuracy: 0.5000\n",
      "Epoch 305/400\n",
      "14/14 [==============================] - 2s 179ms/step - loss: 0.0212 - accuracy: 0.9911 - val_loss: 1.9645 - val_accuracy: 0.5357\n",
      "Epoch 306/400\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0491 - accuracy: 0.9911 - val_loss: 2.4613 - val_accuracy: 0.5000\n",
      "Epoch 307/400\n",
      "14/14 [==============================] - 2s 179ms/step - loss: 0.0321 - accuracy: 0.9933 - val_loss: 2.2666 - val_accuracy: 0.4911\n",
      "Epoch 308/400\n",
      "14/14 [==============================] - 3s 186ms/step - loss: 0.0336 - accuracy: 0.9911 - val_loss: 1.9769 - val_accuracy: 0.5357\n",
      "Epoch 309/400\n",
      "14/14 [==============================] - 3s 190ms/step - loss: 0.0496 - accuracy: 0.9888 - val_loss: 1.9615 - val_accuracy: 0.4732\n",
      "Epoch 310/400\n",
      "14/14 [==============================] - 2s 178ms/step - loss: 0.0355 - accuracy: 0.9955 - val_loss: 1.8165 - val_accuracy: 0.4911\n",
      "Epoch 311/400\n",
      "14/14 [==============================] - 2s 181ms/step - loss: 0.0227 - accuracy: 0.9911 - val_loss: 1.7694 - val_accuracy: 0.4643\n",
      "Epoch 312/400\n",
      "14/14 [==============================] - 2s 164ms/step - loss: 0.0254 - accuracy: 0.9888 - val_loss: 1.9158 - val_accuracy: 0.4911\n",
      "Epoch 313/400\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0301 - accuracy: 0.9933 - val_loss: 2.6587 - val_accuracy: 0.5357\n",
      "Epoch 314/400\n",
      "14/14 [==============================] - 2s 178ms/step - loss: 0.0423 - accuracy: 0.9933 - val_loss: 1.7847 - val_accuracy: 0.4643\n",
      "Epoch 315/400\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0309 - accuracy: 0.9888 - val_loss: 1.8385 - val_accuracy: 0.5000\n",
      "Epoch 316/400\n",
      "14/14 [==============================] - 3s 192ms/step - loss: 0.0376 - accuracy: 0.9933 - val_loss: 2.1643 - val_accuracy: 0.5089\n",
      "Epoch 317/400\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.0239 - accuracy: 0.9911 - val_loss: 2.7517 - val_accuracy: 0.5268\n",
      "Epoch 318/400\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0621 - accuracy: 0.9933 - val_loss: 3.1333 - val_accuracy: 0.4821\n",
      "Epoch 319/400\n",
      "14/14 [==============================] - 2s 175ms/step - loss: 0.0412 - accuracy: 0.9888 - val_loss: 2.2280 - val_accuracy: 0.5357\n",
      "Epoch 320/400\n",
      "14/14 [==============================] - 2s 170ms/step - loss: 0.0406 - accuracy: 0.9933 - val_loss: 2.1652 - val_accuracy: 0.5089\n",
      "Epoch 321/400\n",
      "14/14 [==============================] - 2s 172ms/step - loss: 0.0165 - accuracy: 0.9933 - val_loss: 1.7614 - val_accuracy: 0.4643\n",
      "Epoch 322/400\n",
      "14/14 [==============================] - 2s 181ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 2.2743 - val_accuracy: 0.5268\n",
      "Epoch 323/400\n",
      "14/14 [==============================] - 2s 174ms/step - loss: 0.0569 - accuracy: 0.9911 - val_loss: 2.0739 - val_accuracy: 0.5000\n",
      "Epoch 324/400\n",
      "14/14 [==============================] - 3s 190ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 1.7822 - val_accuracy: 0.4732\n",
      "Epoch 325/400\n",
      "14/14 [==============================] - 3s 193ms/step - loss: 0.0626 - accuracy: 0.9866 - val_loss: 1.9763 - val_accuracy: 0.4911\n",
      "Epoch 326/400\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0603 - accuracy: 0.9933 - val_loss: 2.5952 - val_accuracy: 0.5268\n",
      "Epoch 327/400\n",
      "14/14 [==============================] - 2s 152ms/step - loss: 0.0340 - accuracy: 0.9933 - val_loss: 1.8528 - val_accuracy: 0.5000\n",
      "Epoch 328/400\n",
      "14/14 [==============================] - 3s 186ms/step - loss: 0.0488 - accuracy: 0.9911 - val_loss: 1.8920 - val_accuracy: 0.5089\n",
      "Epoch 329/400\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.0365 - accuracy: 0.9911 - val_loss: 2.0776 - val_accuracy: 0.5357\n",
      "Epoch 330/400\n",
      "14/14 [==============================] - 2s 167ms/step - loss: 0.0264 - accuracy: 0.9933 - val_loss: 1.9289 - val_accuracy: 0.5357\n",
      "Epoch 331/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0234 - accuracy: 0.9911 - val_loss: 1.9900 - val_accuracy: 0.4643\n",
      "Epoch 332/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0494 - accuracy: 0.9911 - val_loss: 2.9968 - val_accuracy: 0.5268\n",
      "Epoch 333/400\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.0161 - accuracy: 0.9933 - val_loss: 3.1997 - val_accuracy: 0.4821\n",
      "Epoch 334/400\n",
      "14/14 [==============================] - 2s 168ms/step - loss: 0.0497 - accuracy: 0.9911 - val_loss: 2.2492 - val_accuracy: 0.5446\n",
      "Epoch 335/400\n",
      "14/14 [==============================] - 2s 160ms/step - loss: 0.0203 - accuracy: 0.9933 - val_loss: 1.8235 - val_accuracy: 0.4732\n",
      "Epoch 336/400\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0341 - accuracy: 0.9888 - val_loss: 2.7486 - val_accuracy: 0.5179\n",
      "Epoch 337/400\n",
      "14/14 [==============================] - 2s 180ms/step - loss: 0.0264 - accuracy: 0.9933 - val_loss: 1.8308 - val_accuracy: 0.4911\n",
      "Epoch 338/400\n",
      "14/14 [==============================] - 2s 176ms/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 1.8114 - val_accuracy: 0.4821\n",
      "Epoch 339/400\n",
      "14/14 [==============================] - 3s 188ms/step - loss: 0.0282 - accuracy: 0.9888 - val_loss: 2.2197 - val_accuracy: 0.5625\n",
      "Epoch 340/400\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.0319 - accuracy: 0.9911 - val_loss: 2.2815 - val_accuracy: 0.5446\n",
      "Epoch 341/400\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0420 - accuracy: 0.9933 - val_loss: 2.8006 - val_accuracy: 0.4821\n",
      "Epoch 342/400\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0425 - accuracy: 0.9933 - val_loss: 1.7971 - val_accuracy: 0.4732\n",
      "Epoch 343/400\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0438 - accuracy: 0.9911 - val_loss: 2.1884 - val_accuracy: 0.5268\n",
      "Epoch 344/400\n",
      "14/14 [==============================] - 2s 156ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 1.7905 - val_accuracy: 0.4554\n",
      "Epoch 345/400\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.0390 - accuracy: 0.9911 - val_loss: 2.6990 - val_accuracy: 0.5268\n",
      "Epoch 346/400\n",
      "14/14 [==============================] - 2s 168ms/step - loss: 0.0321 - accuracy: 0.9933 - val_loss: 3.9058 - val_accuracy: 0.4821\n",
      "Epoch 347/400\n",
      "14/14 [==============================] - 2s 159ms/step - loss: 0.0316 - accuracy: 0.9911 - val_loss: 2.6255 - val_accuracy: 0.5179\n",
      "Epoch 348/400\n",
      "14/14 [==============================] - 2s 175ms/step - loss: 0.0235 - accuracy: 0.9955 - val_loss: 1.9345 - val_accuracy: 0.4911\n",
      "Epoch 349/400\n",
      "14/14 [==============================] - 2s 167ms/step - loss: 0.0228 - accuracy: 0.9933 - val_loss: 2.3968 - val_accuracy: 0.5357\n",
      "Epoch 350/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0399 - accuracy: 0.9911 - val_loss: 3.1698 - val_accuracy: 0.4821\n",
      "Epoch 351/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0746 - accuracy: 0.9888 - val_loss: 2.6520 - val_accuracy: 0.4911\n",
      "Epoch 352/400\n",
      "14/14 [==============================] - 2s 140ms/step - loss: 0.0270 - accuracy: 0.9978 - val_loss: 2.4545 - val_accuracy: 0.5625\n",
      "Epoch 353/400\n",
      "14/14 [==============================] - 2s 142ms/step - loss: 0.0605 - accuracy: 0.9866 - val_loss: 1.7934 - val_accuracy: 0.4911\n",
      "Epoch 354/400\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.0351 - accuracy: 0.9911 - val_loss: 1.7178 - val_accuracy: 0.4732\n",
      "Epoch 355/400\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.0367 - accuracy: 0.9933 - val_loss: 2.8983 - val_accuracy: 0.5357\n",
      "Epoch 356/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0443 - accuracy: 0.9911 - val_loss: 1.9109 - val_accuracy: 0.5000\n",
      "Epoch 357/400\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.0202 - accuracy: 0.9955 - val_loss: 2.8479 - val_accuracy: 0.5268\n",
      "Epoch 358/400\n",
      "14/14 [==============================] - 2s 138ms/step - loss: 0.0286 - accuracy: 0.9955 - val_loss: 2.9320 - val_accuracy: 0.4732\n",
      "Epoch 359/400\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 0.0282 - accuracy: 0.9911 - val_loss: 2.2351 - val_accuracy: 0.5357\n",
      "Epoch 360/400\n",
      "14/14 [==============================] - 2s 142ms/step - loss: 0.0278 - accuracy: 0.9933 - val_loss: 2.0316 - val_accuracy: 0.4732\n",
      "Epoch 361/400\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.0329 - accuracy: 0.9911 - val_loss: 1.7754 - val_accuracy: 0.4732\n",
      "Epoch 362/400\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.0284 - accuracy: 0.9933 - val_loss: 1.9760 - val_accuracy: 0.4911\n",
      "Epoch 363/400\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.0376 - accuracy: 0.9911 - val_loss: 2.1284 - val_accuracy: 0.5446\n",
      "Epoch 364/400\n",
      "14/14 [==============================] - 2s 148ms/step - loss: 0.0376 - accuracy: 0.9911 - val_loss: 2.2560 - val_accuracy: 0.4911\n",
      "Epoch 365/400\n",
      "14/14 [==============================] - 2s 161ms/step - loss: 0.0500 - accuracy: 0.9933 - val_loss: 2.9235 - val_accuracy: 0.5268\n",
      "Epoch 366/400\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 2.4959 - val_accuracy: 0.5000\n",
      "Epoch 367/400\n",
      "14/14 [==============================] - 2s 151ms/step - loss: 0.0152 - accuracy: 0.9955 - val_loss: 3.2552 - val_accuracy: 0.5179\n",
      "Epoch 368/400\n",
      "14/14 [==============================] - 2s 154ms/step - loss: 0.0368 - accuracy: 0.9955 - val_loss: 3.2748 - val_accuracy: 0.4732\n",
      "Epoch 369/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0480 - accuracy: 0.9933 - val_loss: 3.4089 - val_accuracy: 0.4732\n",
      "Epoch 370/400\n",
      "14/14 [==============================] - 2s 142ms/step - loss: 0.0395 - accuracy: 0.9911 - val_loss: 1.9916 - val_accuracy: 0.4911\n",
      "Epoch 371/400\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.0599 - accuracy: 0.9933 - val_loss: 2.0428 - val_accuracy: 0.5357\n",
      "Epoch 372/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0120 - accuracy: 0.9933 - val_loss: 3.6347 - val_accuracy: 0.4732\n",
      "Epoch 373/400\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.0193 - accuracy: 0.9911 - val_loss: 1.8457 - val_accuracy: 0.4911\n",
      "Epoch 374/400\n",
      "14/14 [==============================] - 2s 146ms/step - loss: 0.0414 - accuracy: 0.9933 - val_loss: 2.6054 - val_accuracy: 0.4911\n",
      "Epoch 375/400\n",
      "14/14 [==============================] - 2s 149ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 1.8546 - val_accuracy: 0.4911\n",
      "Epoch 376/400\n",
      "14/14 [==============================] - 2s 153ms/step - loss: 0.0311 - accuracy: 0.9933 - val_loss: 3.1918 - val_accuracy: 0.4821\n",
      "Epoch 377/400\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.0407 - accuracy: 0.9911 - val_loss: 1.8258 - val_accuracy: 0.4732\n",
      "Epoch 378/400\n",
      "14/14 [==============================] - 2s 157ms/step - loss: 0.0338 - accuracy: 0.9911 - val_loss: 1.8774 - val_accuracy: 0.5089\n",
      "Epoch 379/400\n",
      "14/14 [==============================] - 3s 185ms/step - loss: 0.0347 - accuracy: 0.9911 - val_loss: 1.9485 - val_accuracy: 0.5357\n",
      "Epoch 380/400\n",
      "14/14 [==============================] - 2s 145ms/step - loss: 0.0293 - accuracy: 0.9911 - val_loss: 1.8718 - val_accuracy: 0.4911\n",
      "Epoch 381/400\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 2.3920 - val_accuracy: 0.5357\n",
      "Epoch 382/400\n",
      "14/14 [==============================] - 2s 137ms/step - loss: 0.0416 - accuracy: 0.9888 - val_loss: 1.8860 - val_accuracy: 0.4821\n",
      "Epoch 383/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0350 - accuracy: 0.9888 - val_loss: 1.9692 - val_accuracy: 0.5179\n",
      "Epoch 384/400\n",
      "14/14 [==============================] - 2s 155ms/step - loss: 0.0316 - accuracy: 0.9911 - val_loss: 2.2241 - val_accuracy: 0.5179\n",
      "Epoch 385/400\n",
      "14/14 [==============================] - 2s 150ms/step - loss: 0.0393 - accuracy: 0.9911 - val_loss: 1.8288 - val_accuracy: 0.5000\n",
      "Epoch 386/400\n",
      "14/14 [==============================] - 2s 139ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 1.8257 - val_accuracy: 0.5000\n",
      "Epoch 387/400\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.0263 - accuracy: 0.9888 - val_loss: 1.8384 - val_accuracy: 0.5179\n",
      "Epoch 388/400\n",
      "14/14 [==============================] - 2s 144ms/step - loss: 0.0472 - accuracy: 0.9911 - val_loss: 2.6530 - val_accuracy: 0.5268\n",
      "Epoch 389/400\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.0593 - accuracy: 0.9888 - val_loss: 1.8750 - val_accuracy: 0.5357\n",
      "Epoch 390/400\n",
      "14/14 [==============================] - 2s 135ms/step - loss: 0.0414 - accuracy: 0.9955 - val_loss: 2.7114 - val_accuracy: 0.4911\n",
      "Epoch 391/400\n",
      "14/14 [==============================] - 2s 139ms/step - loss: 0.0328 - accuracy: 0.9955 - val_loss: 2.0744 - val_accuracy: 0.5446\n",
      "Epoch 392/400\n",
      "14/14 [==============================] - 2s 144ms/step - loss: 0.0371 - accuracy: 0.9911 - val_loss: 1.9077 - val_accuracy: 0.5089\n",
      "Epoch 393/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 2.7783 - val_accuracy: 0.5357\n",
      "Epoch 394/400\n",
      "14/14 [==============================] - 2s 165ms/step - loss: 0.0303 - accuracy: 0.9933 - val_loss: 4.0471 - val_accuracy: 0.4732\n",
      "Epoch 395/400\n",
      "14/14 [==============================] - 2s 141ms/step - loss: 0.0449 - accuracy: 0.9955 - val_loss: 2.5909 - val_accuracy: 0.5268\n",
      "Epoch 396/400\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.0189 - accuracy: 0.9933 - val_loss: 1.9904 - val_accuracy: 0.5089\n",
      "Epoch 397/400\n",
      "14/14 [==============================] - 2s 143ms/step - loss: 0.0252 - accuracy: 0.9933 - val_loss: 2.5290 - val_accuracy: 0.5179\n",
      "Epoch 398/400\n",
      "14/14 [==============================] - 2s 158ms/step - loss: 0.0175 - accuracy: 0.9933 - val_loss: 2.7803 - val_accuracy: 0.4911\n",
      "Epoch 399/400\n",
      "14/14 [==============================] - 2s 166ms/step - loss: 0.0564 - accuracy: 0.9911 - val_loss: 3.3221 - val_accuracy: 0.5268\n",
      "Epoch 400/400\n",
      "14/14 [==============================] - 2s 147ms/step - loss: 0.0116 - accuracy: 0.9955 - val_loss: 3.2884 - val_accuracy: 0.4821\n",
      "val_loss: 3.288381814956665 val_accuracy: 0.4821428656578064\n",
      "4/4 [==============================] - 0s 43ms/step\n",
      "El algoritmo acerto 54 veces sobre los 112 casos.\n"
     ]
    }
   ],
   "source": [
    "#50 0.77\n",
    "model = new_RNN()\n",
    "model.summary()\n",
    "#https://keras.io/api/callbacks/early_stopping/\n",
    "callbacks = []\n",
    "'''\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        min_delta=0.01, #si un epochs mejora como un min_delta respecto a la anterior, no contara como mejora\n",
    "        patience=70,#numero de epochs sin mejoras que se tendra paciencia\n",
    "        verbose=1,#mostrar informacion extra, 0 no mostrar\n",
    "     )\n",
    "]\n",
    "'''\n",
    "num_epochs = 400\n",
    "num_batch_size = 20\n",
    "start = datetime.datetime.now()\n",
    "   \n",
    "results = model.fit(X_train, y_train,epochs=num_epochs, validation_data=(X_test, y_test),callbacks=callbacks)\n",
    "duration = datetime.datetime.now() - start\n",
    "test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"val_loss: {test_accuracy[0]}\", f\"val_accuracy: {test_accuracy[1]}\")\n",
    "y_values = model.predict(X_test)\n",
    "y_prediction=[([1,0] if i[0]>i[1] else [0,1]) for i in y_values]\n",
    "y_i = len(y_values)\n",
    "i = 0\n",
    "true_values = 0\n",
    "while (i < y_i):\n",
    "    true_values += (1 if (y_test[i][0] == y_prediction[i][0] or y_test[i][1] == y_prediction[i][1]) else 0)\n",
    "    i = i + 1 \n",
    "print(f\"El algoritmo acerto {true_values} veces sobre los {y_i} casos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff7da6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 5.53353283e-12],\n",
       "       [1.00000000e+00, 3.29680149e-27],\n",
       "       [1.00000000e+00, 1.66489030e-35],\n",
       "       [1.00000000e+00, 9.89839766e-09],\n",
       "       [1.00000000e+00, 2.94481365e-19],\n",
       "       [9.99999642e-01, 3.85474550e-07],\n",
       "       [1.00000000e+00, 2.51310475e-25],\n",
       "       [1.00000000e+00, 2.79681290e-30],\n",
       "       [1.00000000e+00, 2.49083749e-18],\n",
       "       [1.00000000e+00, 2.71262942e-35],\n",
       "       [1.00000000e+00, 9.23170784e-09],\n",
       "       [9.99999642e-01, 3.20412823e-07],\n",
       "       [1.00000000e+00, 2.88399015e-35],\n",
       "       [1.00000000e+00, 5.28735851e-20],\n",
       "       [1.00000000e+00, 1.66164994e-14],\n",
       "       [1.00000000e+00, 1.07073723e-31],\n",
       "       [1.00000000e+00, 5.21076160e-08],\n",
       "       [1.00000000e+00, 7.06373975e-31],\n",
       "       [1.00000000e+00, 7.03734959e-10],\n",
       "       [1.00000000e+00, 2.34850301e-24],\n",
       "       [1.00000000e+00, 2.79560551e-24],\n",
       "       [1.00000000e+00, 1.19134979e-30],\n",
       "       [6.82766722e-06, 9.99993205e-01],\n",
       "       [1.00000000e+00, 6.47394494e-09],\n",
       "       [1.00000000e+00, 5.74454253e-20],\n",
       "       [1.00000000e+00, 1.61013425e-09],\n",
       "       [1.00000000e+00, 9.61438706e-10],\n",
       "       [1.00000000e+00, 1.96863552e-24],\n",
       "       [1.00000000e+00, 2.26115551e-15],\n",
       "       [1.00000000e+00, 2.66758122e-12],\n",
       "       [1.00000000e+00, 4.33083151e-37],\n",
       "       [1.00000000e+00, 1.41425893e-33],\n",
       "       [9.90157008e-01, 9.84297600e-03],\n",
       "       [1.00000000e+00, 1.17377631e-35],\n",
       "       [1.00000000e+00, 5.41420517e-37],\n",
       "       [9.99282777e-01, 7.17215240e-04],\n",
       "       [1.00000000e+00, 1.58228292e-10],\n",
       "       [9.59438086e-01, 4.05618846e-02],\n",
       "       [1.00000000e+00, 1.53785438e-25],\n",
       "       [1.00000000e+00, 2.65783698e-22],\n",
       "       [1.00000000e+00, 1.59558243e-16],\n",
       "       [1.00000000e+00, 6.04148949e-34],\n",
       "       [1.00000000e+00, 1.81504778e-14],\n",
       "       [1.00000000e+00, 7.94950748e-20],\n",
       "       [1.00000000e+00, 2.24123991e-16],\n",
       "       [1.00000000e+00, 9.34178238e-15],\n",
       "       [1.00000000e+00, 3.96883625e-27],\n",
       "       [1.00000000e+00, 7.60842708e-27],\n",
       "       [1.00000000e+00, 1.11929655e-17],\n",
       "       [1.00000000e+00, 1.29601030e-34],\n",
       "       [1.00000000e+00, 3.08773431e-15],\n",
       "       [1.00000000e+00, 5.53094548e-09],\n",
       "       [1.00000000e+00, 1.19201868e-29],\n",
       "       [1.00000000e+00, 1.78419768e-21],\n",
       "       [1.00000000e+00, 9.54947499e-09],\n",
       "       [1.00000000e+00, 3.46814455e-34],\n",
       "       [1.00000000e+00, 1.07617616e-22],\n",
       "       [1.00000000e+00, 1.08470823e-21],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 1.66703374e-18],\n",
       "       [1.00000000e+00, 9.88199830e-29],\n",
       "       [1.00000000e+00, 8.44999788e-31],\n",
       "       [1.00000000e+00, 3.70842539e-16],\n",
       "       [9.99997735e-01, 2.31644344e-06],\n",
       "       [1.00000000e+00, 2.77753760e-22],\n",
       "       [1.00000000e+00, 1.95220865e-21],\n",
       "       [1.00000000e+00, 9.61215537e-20],\n",
       "       [1.00000000e+00, 2.89197066e-17],\n",
       "       [1.00000000e+00, 1.01153576e-17],\n",
       "       [1.00000000e+00, 5.08786222e-15],\n",
       "       [1.00000000e+00, 1.93193599e-32],\n",
       "       [1.00000000e+00, 1.48896954e-12],\n",
       "       [1.00000000e+00, 9.77597495e-27],\n",
       "       [9.79515076e-01, 2.04849187e-02],\n",
       "       [1.00000000e+00, 2.56907710e-29],\n",
       "       [1.00000000e+00, 5.38324510e-17],\n",
       "       [1.00000000e+00, 5.60023626e-15],\n",
       "       [1.00000000e+00, 9.51795372e-18],\n",
       "       [1.00000000e+00, 1.07559025e-35],\n",
       "       [1.00000000e+00, 1.55302898e-25],\n",
       "       [1.00000000e+00, 2.53946442e-23],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 6.04653216e-10],\n",
       "       [1.00000000e+00, 6.04148949e-34],\n",
       "       [1.00000000e+00, 7.19116295e-26],\n",
       "       [1.00000000e+00, 8.92613659e-23],\n",
       "       [1.00000000e+00, 1.72639166e-27],\n",
       "       [1.00000000e+00, 9.90930168e-12],\n",
       "       [1.00000000e+00, 3.07273873e-09],\n",
       "       [1.00000000e+00, 1.83497770e-12],\n",
       "       [1.00000000e+00, 9.77101325e-35],\n",
       "       [1.00000000e+00, 8.76897237e-21],\n",
       "       [1.00000000e+00, 2.53294230e-09],\n",
       "       [9.99975801e-01, 2.41804264e-05],\n",
       "       [1.00000000e+00, 1.67336373e-14],\n",
       "       [1.00000000e+00, 1.21201339e-24],\n",
       "       [1.00000000e+00, 6.68265916e-17],\n",
       "       [1.00000000e+00, 3.83870188e-31],\n",
       "       [1.00000000e+00, 1.59561979e-30],\n",
       "       [1.00000000e+00, 1.43608316e-15],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 1.00503422e-27],\n",
       "       [1.00000000e+00, 8.73944697e-37],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [9.99509096e-01, 4.90874227e-04],\n",
       "       [1.00000000e+00, 2.76068137e-20],\n",
       "       [1.00000000e+00, 1.33469883e-19],\n",
       "       [1.00000000e+00, 5.92559057e-10],\n",
       "       [1.00000000e+00, 1.45142915e-27],\n",
       "       [1.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "47073eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = results.history['loss']\n",
    "test_loss = results.history['val_loss']\n",
    "epochs_range = range(1, len(training_loss) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a72e7f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bad97191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCross-validated score (Accuracy score): 0.8200663349917081\\n-----------------------\\nResumen\\nFold score (Accuracy score): 0.8281573498964804\\nFold score (Accuracy score): 0.8Detector de la mentira usando redes neuronales recurrentes426501035196687\\nFold score (Accuracy score): 0.8008298755186722\\nFold score (Accuracy score): 0.8174273858921162\\nFold score (Accuracy score): 0.8112033195020747\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def new_RNN():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50,input_shape= dim_entrada, return_sequences=False))\n",
    "#    model.add(LSTM(units=16,input_shape= dim_entrada, return_sequences=True))\n",
    "#    model.add(LSTM(units=4,input_shape= dim_entrada, return_sequences=False))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
    "    return model\n",
    "\n",
    "'''\n",
    "Cross-validated score (Accuracy score): 0.8200663349917081\n",
    "-----------------------\n",
    "Resumen\n",
    "Fold score (Accuracy score): 0.8281573498964804\n",
    "Fold score (Accuracy score): 0.8Detector de la mentira usando redes neuronales recurrentes426501035196687\n",
    "Fold score (Accuracy score): 0.8008298755186722\n",
    "Fold score (Accuracy score): 0.8174273858921162\n",
    "Fold score (Accuracy score): 0.8112033195020747\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb0e73ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs_range, training_loss, 'r',marker=\"o\",linestyle=\"--\")\n",
    "plt.plot(epochs_range, test_loss, 'b',marker=\"o\",linestyle=\"-\")\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Error')\n",
    "plt.rcParams[\"figure.figsize\"] = (20,8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d79330e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.40328726172447205 val_accuracy: 0.8150064945220947\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m y_i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y_values)\n\u001b[0;32m      5\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m true_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_values' is not defined"
     ]
    }
   ],
   "source": [
    "test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"val_loss: {test_accuracy[0]}\", f\"val_accuracy: {test_accuracy[1]}\")\n",
    "\n",
    "y_i = len(y_values)\n",
    "i = 0\n",
    "true_values = 0\n",
    "while (i < y_i):\n",
    "    true_values += (1 if (y_test[i][0] == y_prediction[i][0] or y_test[i][1] == y_prediction[i][1]) else 0)\n",
    "    i = i + 1 \n",
    "    \n",
    "print(f\"El algoritmo acerto {true_values} veces sobre los {y_i} casos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "03527f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nval_loss: 0.42675861716270447 val_accuracy: 0.7767857313156128\\nval_loss: 0.44326552748680115 val_accuracy: 0.7611607313156128\\nval_loss: 0.4475260078907013 val_accuracy: 0.7566964030265808\\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "val_loss: 0.42675861716270447 val_accuracy: 0.7767857313156128\n",
    "val_loss: 0.44326552748680115 val_accuracy: 0.7611607313156128\n",
    "val_loss: 0.4475260078907013 val_accuracy: 0.7566964030265808\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f0a73",
   "metadata": {},
   "source": [
    "#### Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9995db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:(2236, 40) y:(2236, 2)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(f\"X:{X.shape} y:{y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b478ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa77694",
   "metadata": {},
   "source": [
    "El bloque realizara el k fold cross validation dividiendolo en 5 folds, se uso los MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4fcbace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_5.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_5.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341515e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
